{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8abd2f3a-7930-44bc-9a5f-3646677309bd",
   "metadata": {},
   "source": [
    "<a href=\"http://cocl.us/pytorch_link_top\">\n",
    "    <img src=\"https://s3-api.us-geo.objectstorage.softlayer.net/cf-courses-data/CognitiveClass/DL0110EN/notebook_images%20/Pytochtop.png\" width=\"750\" alt=\"IBM Product \">\n",
    "</a> \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0b80864-134b-4e19-b978-042c3752181d",
   "metadata": {},
   "source": [
    "<img src=\"https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBMDeveloperSkillsNetwork-DL0321EN-SkillsNetwork/image/IDSN-logo.png\" width=\"200\" alt=\"cognitiveclass.ai logo\">\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e5bdfa8-6014-495e-af4c-1905a13cf122",
   "metadata": {},
   "source": [
    "<h1><h1>Pre-trained-Models with PyTorch </h1>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53741054-55b8-4d99-9976-6032dbb90087",
   "metadata": {},
   "source": [
    "In this lab, you will use pre-trained models to classify between the negative and positive samples; you will be provided with the dataset object. The particular pre-trained model will be resnet18; you will have three questions: \n",
    "<ul>\n",
    "<li>change the output layer</li>\n",
    "<li> train the model</li> \n",
    "<li>  identify  several  misclassified samples</li> \n",
    " </ul>\n",
    "You will take several screenshots of your work and share your notebook. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba3c08cf-34b0-406d-8125-0593277f34bc",
   "metadata": {},
   "source": [
    "<h2>Table of Contents</h2>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "921f07a2-6a2d-4608-84f2-0cc62bf2501b",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\" style=\"margin-top: 20px\">\n",
    "\n",
    "\n",
    "<ul>\n",
    "    <li><a href=\"#download_data\"> Download Data</a></li>\n",
    "    <li><a href=\"#auxiliary\"> Imports and Auxiliary Functions </a></li>\n",
    "    <li><a href=\"#data_class\"> Dataset Class</a></li>\n",
    "    <li><a href=\"#Question_1\">Question 1</a></li>\n",
    "    <li><a href=\"#Question_2\">Question 2</a></li>\n",
    "    <li><a href=\"#Question_3\">Question 3</a></li>\n",
    "</ul>\n",
    "<p>Estimated Time Needed: <strong>120 min</strong></p>\n",
    " </div>\n",
    "<hr>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ceb7083-02ed-4c9c-b5b4-7b0418388a2a",
   "metadata": {},
   "source": [
    "<h2 id=\"download_data\">Download Data</h2>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efedf9be-c643-4d62-8158-0918061c6b8b",
   "metadata": {},
   "source": [
    "Download the dataset and unzip the files in your data directory, unlike the other labs, all the data will be deleted after you close  the lab, this may take some time:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f119a703-4c0b-40c8-9ca9-152a26a98210",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2025-01-19 00:43:32--  https://s3-api.us-geo.objectstorage.softlayer.net/cf-courses-data/CognitiveClass/DL0321EN/data/images/Positive_tensors.zip\n",
      "Resolving s3-api.us-geo.objectstorage.softlayer.net (s3-api.us-geo.objectstorage.softlayer.net)... 67.228.254.196\n",
      "Connecting to s3-api.us-geo.objectstorage.softlayer.net (s3-api.us-geo.objectstorage.softlayer.net)|67.228.254.196|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 2598656062 (2.4G) [application/zip]\n",
      "Saving to: ‘Positive_tensors.zip’\n",
      "\n",
      "Positive_tensors.zi 100%[===================>]   2.42G  36.4MB/s    in 96s     \n",
      "\n",
      "2025-01-19 00:45:10 (25.8 MB/s) - ‘Positive_tensors.zip’ saved [2598656062/2598656062]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!wget https://s3-api.us-geo.objectstorage.softlayer.net/cf-courses-data/CognitiveClass/DL0321EN/data/images/Positive_tensors.zip "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/kronos/Downloads'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e3f2804b-7bc0-4a34-a8bd-0756372003da",
   "metadata": {},
   "outputs": [],
   "source": [
    "!unzip -q Positive_tensors.zip "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e5119dc8-afc5-460d-879a-8b774f567bd0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2025-01-19 00:46:44--  https://s3-api.us-geo.objectstorage.softlayer.net/cf-courses-data/CognitiveClass/DL0321EN/data/images/Negative_tensors.zip\n",
      "Resolving s3-api.us-geo.objectstorage.softlayer.net (s3-api.us-geo.objectstorage.softlayer.net)... 67.228.254.196\n",
      "Connecting to s3-api.us-geo.objectstorage.softlayer.net (s3-api.us-geo.objectstorage.softlayer.net)|67.228.254.196|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 2111408108 (2.0G) [application/zip]\n",
      "Saving to: ‘Negative_tensors.zip’\n",
      "\n",
      "Negative_tensors.zi 100%[===================>]   1.97G  34.1MB/s    in 57s     \n",
      "\n",
      "2025-01-19 00:47:43 (35.1 MB/s) - ‘Negative_tensors.zip’ saved [2111408108/2111408108]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "! wget https://s3-api.us-geo.objectstorage.softlayer.net/cf-courses-data/CognitiveClass/DL0321EN/data/images/Negative_tensors.zip\n",
    "!unzip -q Negative_tensors.zip"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fad15709-e387-40fd-ab2f-8fde44dea3e1",
   "metadata": {},
   "source": [
    "We will install torchvision:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a4397a6-b3f6-4b0e-b9f9-c0e294eede06",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install torchvision"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "720b2e1a-fa06-4daf-a922-4a70777f6709",
   "metadata": {},
   "source": [
    "<h2 id=\"auxiliary\">Imports and Auxiliary Functions</h2>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cadbf87-12b4-4cf5-973b-d074375b21f7",
   "metadata": {},
   "source": [
    "The following are the libraries we are going to use for this lab. The <code>torch.manual_seed()</code> is for forcing the random function to give the same number every time we try to recompile it.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "100c4913-0f97-425c-bf42-eba819ed5f7f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7466da13ee50>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# These are the libraries will be used for this lab.\n",
    "import torchvision.models as models\n",
    "from PIL import Image\n",
    "import pandas\n",
    "from torchvision import transforms\n",
    "import torch.nn as nn\n",
    "import time\n",
    "import torch \n",
    "import matplotlib.pylab as plt\n",
    "import numpy as np\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import h5py\n",
    "import os\n",
    "import glob\n",
    "torch.manual_seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "62927ada-7de8-485c-a08e-cb2b038b25d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.pyplot import imshow\n",
    "import matplotlib.pylab as plt\n",
    "from PIL import Image\n",
    "import pandas as pd\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fed9c29-48b2-4bbf-9ba9-7f6fc1c088a2",
   "metadata": {},
   "source": [
    "<!--Empty Space for separating topics-->\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7b81ceb-2ff9-4e71-b0ad-bcd507f91029",
   "metadata": {},
   "source": [
    "<h2 id=\"data_class\">Dataset Class</h2>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8630dc80-3ee1-40a4-84d7-0427cd7101c7",
   "metadata": {},
   "source": [
    " This dataset class is essentially the same dataset you build in the previous section, but to speed things up, we are going to use tensors instead of jpeg images. Therefor for each iteration, you will skip the reshape step, conversion step to tensors and normalization step.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4c2612bc-5ed4-4f7d-bc9d-71c6a69ce2b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n"
     ]
    }
   ],
   "source": [
    "# Create your own dataset object\n",
    "\n",
    "class Dataset(Dataset):\n",
    "\n",
    "    # Constructor\n",
    "    def __init__(self,transform=None,train=True):\n",
    "        directory=\"/home/kronos/Downloads\"\n",
    "        positive=\"Positive_tensors\"\n",
    "        negative='Negative_tensors'\n",
    "\n",
    "        positive_file_path=os.path.join(directory,positive)\n",
    "        negative_file_path=os.path.join(directory,negative)\n",
    "        positive_files=[os.path.join(positive_file_path,file) for file in os.listdir(positive_file_path) if file.endswith(\".pt\")]\n",
    "        negative_files=[os.path.join(negative_file_path,file) for file in os.listdir(negative_file_path) if file.endswith(\".pt\")]\n",
    "        number_of_samples=len(positive_files)+len(negative_files)\n",
    "        self.all_files=[None]*number_of_samples\n",
    "        self.all_files[::2]=positive_files\n",
    "        self.all_files[1::2]=negative_files \n",
    "        # The transform is goint to be used on image\n",
    "        self.transform = transform\n",
    "        #torch.LongTensor\n",
    "        self.Y=torch.zeros([number_of_samples]).type(torch.LongTensor)\n",
    "        self.Y[::2]=1\n",
    "        self.Y[1::2]=0\n",
    "        \n",
    "        if train:\n",
    "            self.all_files=self.all_files[0:30000]\n",
    "            self.Y=self.Y[0:30000]\n",
    "            self.len=len(self.all_files)\n",
    "        else:\n",
    "            self.all_files=self.all_files[30000:]\n",
    "            self.Y=self.Y[30000:]\n",
    "            self.len=len(self.all_files)     \n",
    "       \n",
    "    # Get the length\n",
    "    def __len__(self):\n",
    "        return self.len\n",
    "    \n",
    "    # Getter\n",
    "    def __getitem__(self, idx):\n",
    "               \n",
    "        image=torch.load(self.all_files[idx])\n",
    "        y=self.Y[idx]\n",
    "                  \n",
    "        # If there is any transform method, apply it onto the image\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        return image, y\n",
    "    \n",
    "print(\"done\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "747173bb-89d3-45e8-b058-ab209f14610c",
   "metadata": {},
   "source": [
    "We create two dataset objects, one for the training data and one for the validation data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0618234d-d2a4-459a-aed0-20e3803a4661",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n"
     ]
    }
   ],
   "source": [
    "train_dataset = Dataset(train=True)\n",
    "validation_dataset = Dataset(train=False)\n",
    "print(\"done\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d03d6186-c5e3-4594-b469-fc776d407fe5",
   "metadata": {},
   "source": [
    "<h2 id=\"Question_1\">Question 1</h2>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67c3bc6f-c9ce-4bc6-98e2-160b4c2c6be3",
   "metadata": {},
   "source": [
    "<b>Prepare a pre-trained resnet18 model :</b>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cdd3ebc-0de2-4418-9316-a20a12ec7034",
   "metadata": {},
   "source": [
    "<b>Step 1</b>: Load the pre-trained model <code>resnet18</code> Set the parameter <code>pretrained</code> to true:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "293cde0f-d36f-4584-a1ff-d4fe736b9fb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Load the pre-trained model resnet18\n",
    "import torchvision.models as models\n",
    "# Type your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89b310a4-2eb5-4627-ae5e-d0783ba838ad",
   "metadata": {},
   "source": [
    "<b>Step 2</b>: Set the attribute <code>requires_grad</code> to <code>False</code>. As a result, the parameters will not be affected by training.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "22ed14f3-ded5-47a6-b667-34e9d5bc0b95",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[0.9303, 0.9646, 1.0159,  ..., 0.4166, 0.3994, 0.3652],\n",
      "         [0.9132, 0.9474, 0.9817,  ..., 0.3994, 0.4166, 0.4337],\n",
      "         [0.9132, 0.9303, 0.9303,  ..., 0.3823, 0.4679, 0.5536],\n",
      "         ...,\n",
      "         [1.0159, 1.0331, 1.0331,  ..., 0.7933, 0.7933, 0.8104],\n",
      "         [1.0159, 1.0331, 1.0331,  ..., 0.7762, 0.7933, 0.8104],\n",
      "         [1.0159, 1.0331, 1.0331,  ..., 0.7591, 0.7933, 0.8104]],\n",
      "\n",
      "        [[0.9230, 0.9580, 1.0105,  ..., 0.4153, 0.3978, 0.3627],\n",
      "         [0.9055, 0.9405, 0.9755,  ..., 0.3978, 0.4153, 0.4328],\n",
      "         [0.9055, 0.9230, 0.9230,  ..., 0.3803, 0.4678, 0.5553],\n",
      "         ...,\n",
      "         [0.9755, 0.9930, 0.9930,  ..., 0.7829, 0.8004, 0.8179],\n",
      "         [0.9755, 0.9930, 0.9930,  ..., 0.7829, 0.8004, 0.8179],\n",
      "         [0.9755, 0.9930, 0.9930,  ..., 0.7654, 0.8004, 0.8179]],\n",
      "\n",
      "        [[0.8448, 0.8797, 0.9319,  ..., 0.3045, 0.2871, 0.2522],\n",
      "         [0.8274, 0.8622, 0.8971,  ..., 0.2871, 0.3045, 0.3219],\n",
      "         [0.8274, 0.8448, 0.8448,  ..., 0.2696, 0.3568, 0.4439],\n",
      "         ...,\n",
      "         [0.8797, 0.8971, 0.8971,  ..., 0.6705, 0.6879, 0.7054],\n",
      "         [0.8797, 0.8971, 0.8971,  ..., 0.6705, 0.6879, 0.7054],\n",
      "         [0.8797, 0.8971, 0.8971,  ..., 0.6531, 0.6879, 0.7054]]])\n",
      "Predicted class index: 600\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_34641/1436567427.py:12: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  tensor = torch.load(\"/home/kronos/Downloads/Positive_tensors/0.pt\")\n"
     ]
    }
   ],
   "source": [
    "# Step 2: Set the parameter cannot be trained for the pre-trained model\n",
    "require_grad = False\n",
    "\n",
    "# Load the pretrained ResNet-50 model\n",
    "model = models.resnet50(weights=models.ResNet50_Weights.IMAGENET1K_V1)\n",
    "\n",
    "# Define preprocessing transformations (must match the model's training)\n",
    "preprocess = models.ResNet50_Weights.IMAGENET1K_V1.transforms()\n",
    "\n",
    "# Load an image\n",
    "tensor = torch.load(\"/home/kronos/Downloads/Positive_tensors/0.pt\")\n",
    "# Apply preprocessing\n",
    "input_tensor = preprocess(tensor).unsqueeze(0)  # Add batch dimension\n",
    "\n",
    "# Perform inference\n",
    "with torch.no_grad():\n",
    "    output = model(input_tensor)\n",
    "\n",
    "# Get predicted class\n",
    "probabilities = torch.nn.functional.softmax(output[0], dim=0)\n",
    "predicted_class = probabilities.argmax().item()\n",
    "\n",
    "print(f\"Predicted class index: {predicted_class}\")\n",
    "model.fc = nn.Linear(2048, 2)\n",
    "# Type your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03f23176-eca4-4e8f-9ec2-a164a5a7ef65",
   "metadata": {},
   "source": [
    "<code>resnet18</code> is used to classify 1000 different objects; as a result, the last layer has 1000 outputs.  The 512 inputs come from the fact that the previously hidden layer has 512 outputs. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "410287ff-6594-4af8-8acc-495106d31545",
   "metadata": {},
   "source": [
    "<b>Step 3</b>: Replace the output layer <code>model.fc</code> of the neural network with a <code>nn.Linear</code> object, to classify 2 different classes. For the parameters <code>in_features </code> remember the last hidden layer has 512 neurons.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "4f79a8c7-4e3c-48b2-8d5c-75ec66fc7b88",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fc = nn.Linear(2048, 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "048fe114-92ee-4c41-aede-1e016711ffcd",
   "metadata": {},
   "source": [
    "Print out the model in order to show whether you get the correct answer.<br> <b>(Your peer reviewer is going to mark based on what you print here.)</b>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "1462f12b-da03-4175-ad74-043e46166410",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ResNet(\n",
      "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
      "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu): ReLU(inplace=True)\n",
      "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "  (layer1): Sequential(\n",
      "    (0): Bottleneck(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): Bottleneck(\n",
      "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (2): Bottleneck(\n",
      "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (layer2): Sequential(\n",
      "    (0): Bottleneck(\n",
      "      (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): Bottleneck(\n",
      "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (2): Bottleneck(\n",
      "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (3): Bottleneck(\n",
      "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (layer3): Sequential(\n",
      "    (0): Bottleneck(\n",
      "      (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (2): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (3): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (4): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (5): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (layer4): Sequential(\n",
      "    (0): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): Bottleneck(\n",
      "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (2): Bottleneck(\n",
      "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "  (fc): Linear(in_features=2048, out_features=2, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb183bcf-8cfa-4e48-93e8-af78f42e57b0",
   "metadata": {},
   "source": [
    "<h2 id=\"Question_2\">Question 2: Train the Model</h2>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91768582-592a-4360-b47c-1c7db7008ff8",
   "metadata": {},
   "source": [
    "In this question you will train your, model:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8455f1a9-a0af-4502-9179-0a4693cf06d8",
   "metadata": {},
   "source": [
    "<b>Step 1</b>: Create a cross entropy criterion function \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "5263c76f-483d-42bf-9716-c526278d3fe5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Create the loss function\n",
    "loss_function = nn.CrossEntropyLoss()\n",
    "# Type your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a14f9645-a2ff-4900-91e7-4acf3eec2427",
   "metadata": {},
   "source": [
    "<b>Step 2</b>: Create a training loader and validation loader object, the batch size should have 100 samples each.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f006c789-b1d6-4eb9-bdc4-613265ac440e",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_loader_train = DataLoader(dataset=train_dataset, batch_size=100)\n",
    "data_loader_validation = DataLoader(dataset=validation_dataset, batch_size=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_34641/3739882169.py:42: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  image=torch.load(self.all_files[idx])\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "'module' object is not callable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[33], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m x, y \u001b[38;5;129;01min\u001b[39;00m data_loader_train:\n\u001b[0;32m----> 2\u001b[0m     \u001b[43mImage\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mTypeError\u001b[0m: 'module' object is not callable"
     ]
    }
   ],
   "source": [
    "for x, y in data_loader_train:\n",
    "    Image(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a965344-294c-4f35-881b-6f3b7e938149",
   "metadata": {},
   "source": [
    "<b>Step 3</b>: Use the following optimizer to minimize the loss \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "4ffbf141-4354-429f-ba64-cf0fecf4d97e",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam([parameters  for parameters in model.parameters() if parameters.requires_grad],lr=0.001)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "278f8e4c-8cc9-477a-b291-3aedf0d0852e",
   "metadata": {},
   "source": [
    "<!--Empty Space for separating topics-->\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a7f9e3b-f4a4-430d-92e4-2b204f4f9162",
   "metadata": {},
   "source": [
    "**Complete the following code to calculate  the accuracy on the validation data for one epoch; this should take about 45 minutes. Make sure you calculate the accuracy on the validation data.**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "e10db4f0-56f4-4c94-940f-133f5764ef04",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_34641/3739882169.py:42: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  image=torch.load(self.all_files[idx])\n"
     ]
    }
   ],
   "source": [
    "n_epochs=1\n",
    "loss_list=[]\n",
    "accuracy_list=[]\n",
    "correct=0\n",
    "N_test=len(validation_dataset)\n",
    "N_train=len(train_dataset)\n",
    "start_time = time.time()\n",
    "#n_epochs\n",
    "\n",
    "Loss=0\n",
    "start_time = time.time()\n",
    "for epoch in range(n_epochs):\n",
    "    for x, y in data_loader_train:\n",
    "\n",
    "        model.train() \n",
    "        optimizer.zero_grad()\n",
    "     \n",
    "        #make a prediction \n",
    "        z=model(x)\n",
    "        # calculate loss \n",
    "        loss=loss_function(z,y)\n",
    "        # calculate gradients of parameters \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        # update parameters \n",
    "        \n",
    "        loss_list.append(loss.data)\n",
    "    correct=0\n",
    "    for x_test, y_test in data_loader_validation:\n",
    "        # set model to eval \n",
    "        model.eval()\n",
    "        #make a prediction \n",
    "        z=model(x_test)\n",
    "        #find max \n",
    "        _,yhat=torch.max(z.data,1)\n",
    "       \n",
    "       \n",
    "        #Calculate misclassified  samples in mini-batch \n",
    "        #hint +=(yhat==y_test).sum().item()\n",
    "        correct+=(yhat==y_test).sum().item()\n",
    "        \n",
    "   \n",
    "    accuracy=correct/N_test\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "176f3003-c65d-40bc-96ad-5c9c48c99f3b",
   "metadata": {},
   "source": [
    "<b>Print out the Accuracy and plot the loss stored in the list <code>loss_list</code> for every iteration and take a screen shot.</b>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "f321eee5-544b-4659-839f-0e6ea591d09d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.994"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "3c7ae1d7-abbd-4e21-b0f2-9e45b967a1b6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(loss_list)\n",
    "plt.xlabel(\"iteration\")\n",
    "plt.ylabel(\"loss\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7f1f6bc-f2ba-4b06-9109-7778966e1379",
   "metadata": {},
   "source": [
    "<h2 id=\"Question_3\">Question 3:Find the misclassified samples</h2> \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a78f947-6f88-4871-8005-d5732cd8e2d9",
   "metadata": {},
   "source": [
    "<b>Identify the first four misclassified samples using the validation data:</b>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "6d0864db-4423-447e-b379-407e707efb43",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_34641/3739882169.py:42: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  image=torch.load(self.all_files[idx])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Misclassified Samples:\n",
      "Sample 1: True Label = 0, Predicted Label = 1\n",
      "Sample 2: True Label = 1, Predicted Label = 0\n",
      "Sample 3: True Label = 1, Predicted Label = 0\n",
      "Sample 4: True Label = 1, Predicted Label = 0\n"
     ]
    }
   ],
   "source": [
    "# Initialize variables to store misclassified samples\n",
    "misclassified_samples = []\n",
    "misclassified_labels = []\n",
    "\n",
    "# Iterate through the validation data to identify misclassified samples\n",
    "for x_test, y_test in data_loader_validation:\n",
    "    model.eval()  # Set model to evaluation mode\n",
    "    z = model(x_test)  # Make predictions\n",
    "    _, yhat = torch.max(z.data, 1)  # Get predicted labels\n",
    "\n",
    "    # Find misclassified samples\n",
    "    for i in range(len(y_test)):\n",
    "        if yhat[i] != y_test[i]:  # Check if prediction is incorrect\n",
    "            misclassified_samples.append(x_test[i])  # Store the input sample\n",
    "            misclassified_labels.append((y_test[i].item(), yhat[i].item()))  # Store true/predicted labels\n",
    "\n",
    "        # Stop once we have 4 misclassified samples\n",
    "        if len(misclassified_samples) == 4:\n",
    "            break\n",
    "    if len(misclassified_samples) == 4:\n",
    "        break\n",
    "\n",
    "# Output the first four misclassified samples and their true/predicted labels\n",
    "print(\"Misclassified Samples:\")\n",
    "for i in range(len(misclassified_samples)):\n",
    "    print(f\"Sample {i+1}: True Label = {misclassified_labels[i][0]}, Predicted Label = {misclassified_labels[i][1]}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "715b8fe6-26bd-4bb9-b8da-1ca492528ee6",
   "metadata": {},
   "source": [
    "<a href=\"https://dataplatform.cloud.ibm.com/docs/content/wsj/analyze-data/share-notebooks.html?utm_source=Exinfluencer&utm_content=000026UJ&utm_id=NA-SkillsNetwork-Channel-SkillsNetworkCoursesIBMDeveloperSkillsNetworkDL0321ENSkillsNetwork951-2022-01-01&utm_medium=Exinfluencer&utm_term=10006555\"> CLICK HERE </a> Click here to see how to share your notebook.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46f20a3f-7d1b-4aea-9e74-e373ec30e1bb",
   "metadata": {},
   "source": [
    "<h2>About the Authors:</h2> \n",
    "\n",
    "<a href=\"https://www.linkedin.com/in/joseph-s-50398b136/?utm_medium=Exinfluencer&utm_source=Exinfluencer&utm_content=000026UJ&utm_term=10006555&utm_id=NA-SkillsNetwork-Channel-SkillsNetworkCoursesIBMDeveloperSkillsNetworkDL0321ENSkillsNetwork951-2022-01-01\">Joseph Santarcangelo</a> has a PhD in Electrical Engineering, his research focused on using machine learning, signal processing, and computer vision to determine how videos impact human cognition. Joseph has been working for IBM since he completed his PhD.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acb64cce-3fe5-489d-bced-79c3e7a447cf",
   "metadata": {},
   "source": [
    "\n",
    "## Change Log\n",
    "\n",
    "|  Date (YYYY-MM-DD) |  Version | Changed By  |  Change Description |\n",
    "|---|---|---|---|\n",
    "| 2020-09-21  | 2.0  | Shubham  |  Migrated Lab to Markdown and added to course repo in GitLab |\n",
    "\n",
    "\n",
    "\n",
    "<hr>\n",
    "\n",
    "## <h3 align=\"center\"> © IBM Corporation 2020. All rights reserved. <h3/>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a379170-e56f-40f9-9f8f-e3227416419a",
   "metadata": {},
   "source": [
    "Copyright &copy; 2018 <a href=\"cognitiveclass.ai?utm_source=bducopyrightlink&utm_medium=dswb&utm_campaign=bdu\">cognitiveclass.ai</a>. This notebook and its source code are released under the terms of the <a href=\"https://bigdatauniversity.com/mit-license/?utm_medium=Exinfluencer&utm_source=Exinfluencer&utm_content=000026UJ&utm_term=10006555&utm_id=NA-SkillsNetwork-Channel-SkillsNetworkCoursesIBMDeveloperSkillsNetworkDL0321ENSkillsNetwork951-2022-01-01\">MIT License</a>.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
