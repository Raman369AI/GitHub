{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Unrecognized configuration class <class 'transformers.models.t5.configuration_t5.T5Config'> for this kind of AutoModel: AutoModelForCausalLM.\nModel type should be one of AriaTextConfig, BambaConfig, BartConfig, BertConfig, BertGenerationConfig, BigBirdConfig, BigBirdPegasusConfig, BioGptConfig, BlenderbotConfig, BlenderbotSmallConfig, BloomConfig, CamembertConfig, LlamaConfig, CodeGenConfig, CohereConfig, Cohere2Config, CpmAntConfig, CTRLConfig, Data2VecTextConfig, DbrxConfig, DiffLlamaConfig, ElectraConfig, Emu3Config, ErnieConfig, FalconConfig, FalconMambaConfig, FuyuConfig, GemmaConfig, Gemma2Config, GitConfig, GlmConfig, GPT2Config, GPT2Config, GPTBigCodeConfig, GPTNeoConfig, GPTNeoXConfig, GPTNeoXJapaneseConfig, GPTJConfig, GraniteConfig, GraniteMoeConfig, JambaConfig, JetMoeConfig, LlamaConfig, MambaConfig, Mamba2Config, MarianConfig, MBartConfig, MegaConfig, MegatronBertConfig, MistralConfig, MixtralConfig, MllamaConfig, MoshiConfig, MptConfig, MusicgenConfig, MusicgenMelodyConfig, MvpConfig, NemotronConfig, OlmoConfig, Olmo2Config, OlmoeConfig, OpenLlamaConfig, OpenAIGPTConfig, OPTConfig, PegasusConfig, PersimmonConfig, PhiConfig, Phi3Config, PhimoeConfig, PLBartConfig, ProphetNetConfig, QDQBertConfig, Qwen2Config, Qwen2MoeConfig, RecurrentGemmaConfig, ReformerConfig, RemBertConfig, RobertaConfig, RobertaPreLayerNormConfig, RoCBertConfig, RoFormerConfig, RwkvConfig, Speech2Text2Config, StableLmConfig, Starcoder2Config, TransfoXLConfig, TrOCRConfig, WhisperConfig, XGLMConfig, XLMConfig, XLMProphetNetConfig, XLMRobertaConfig, XLMRobertaXLConfig, XLNetConfig, XmodConfig, ZambaConfig.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 12\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mlangchain_huggingface\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m HuggingFacePipeline\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtransformers\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m AutoModelForCausalLM, AutoTokenizer, pipeline\n\u001b[0;32m---> 12\u001b[0m llm \u001b[38;5;241m=\u001b[39m \u001b[43mHuggingFacePipeline\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_model_id\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     13\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mgoogle/flan-t5-small\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     14\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtext-generation\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     15\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpipeline_kwargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmax_new_tokens\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     16\u001b[0m \u001b[43m)\u001b[49m\n\u001b[1;32m     18\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mgradio\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mgr\u001b[39;00m\n\u001b[1;32m     19\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mos\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/rapids-24.12/lib/python3.12/site-packages/langchain_huggingface/llms/huggingface_pipeline.py:155\u001b[0m, in \u001b[0;36mHuggingFacePipeline.from_model_id\u001b[0;34m(cls, model_id, task, backend, device, device_map, model_kwargs, pipeline_kwargs, batch_size, **kwargs)\u001b[0m\n\u001b[1;32m    151\u001b[0m             model \u001b[38;5;241m=\u001b[39m OVModelForCausalLM\u001b[38;5;241m.\u001b[39mfrom_pretrained(\n\u001b[1;32m    152\u001b[0m                 model_id, export\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m_model_kwargs\n\u001b[1;32m    153\u001b[0m             )\n\u001b[1;32m    154\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 155\u001b[0m         model \u001b[38;5;241m=\u001b[39m \u001b[43mAutoModelForCausalLM\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_pretrained\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    156\u001b[0m \u001b[43m            \u001b[49m\u001b[43mmodel_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m_model_kwargs\u001b[49m\n\u001b[1;32m    157\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    158\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m task \u001b[38;5;129;01min\u001b[39;00m (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtext2text-generation\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msummarization\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtranslation\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m    159\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m backend \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mopenvino\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n",
      "File \u001b[0;32m~/anaconda3/envs/rapids-24.12/lib/python3.12/site-packages/transformers/models/auto/auto_factory.py:567\u001b[0m, in \u001b[0;36m_BaseAutoModelClass.from_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, *model_args, **kwargs)\u001b[0m\n\u001b[1;32m    563\u001b[0m     model_class \u001b[38;5;241m=\u001b[39m _get_model_class(config, \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m_model_mapping)\n\u001b[1;32m    564\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m model_class\u001b[38;5;241m.\u001b[39mfrom_pretrained(\n\u001b[1;32m    565\u001b[0m         pretrained_model_name_or_path, \u001b[38;5;241m*\u001b[39mmodel_args, config\u001b[38;5;241m=\u001b[39mconfig, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mhub_kwargs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs\n\u001b[1;32m    566\u001b[0m     )\n\u001b[0;32m--> 567\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    568\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnrecognized configuration class \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mconfig\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m for this kind of AutoModel: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    569\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mModel type should be one of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(c\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mfor\u001b[39;00m\u001b[38;5;250m \u001b[39mc\u001b[38;5;250m \u001b[39m\u001b[38;5;129;01min\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m_model_mapping\u001b[38;5;241m.\u001b[39mkeys())\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    570\u001b[0m )\n",
      "\u001b[0;31mValueError\u001b[0m: Unrecognized configuration class <class 'transformers.models.t5.configuration_t5.T5Config'> for this kind of AutoModel: AutoModelForCausalLM.\nModel type should be one of AriaTextConfig, BambaConfig, BartConfig, BertConfig, BertGenerationConfig, BigBirdConfig, BigBirdPegasusConfig, BioGptConfig, BlenderbotConfig, BlenderbotSmallConfig, BloomConfig, CamembertConfig, LlamaConfig, CodeGenConfig, CohereConfig, Cohere2Config, CpmAntConfig, CTRLConfig, Data2VecTextConfig, DbrxConfig, DiffLlamaConfig, ElectraConfig, Emu3Config, ErnieConfig, FalconConfig, FalconMambaConfig, FuyuConfig, GemmaConfig, Gemma2Config, GitConfig, GlmConfig, GPT2Config, GPT2Config, GPTBigCodeConfig, GPTNeoConfig, GPTNeoXConfig, GPTNeoXJapaneseConfig, GPTJConfig, GraniteConfig, GraniteMoeConfig, JambaConfig, JetMoeConfig, LlamaConfig, MambaConfig, Mamba2Config, MarianConfig, MBartConfig, MegaConfig, MegatronBertConfig, MistralConfig, MixtralConfig, MllamaConfig, MoshiConfig, MptConfig, MusicgenConfig, MusicgenMelodyConfig, MvpConfig, NemotronConfig, OlmoConfig, Olmo2Config, OlmoeConfig, OpenLlamaConfig, OpenAIGPTConfig, OPTConfig, PegasusConfig, PersimmonConfig, PhiConfig, Phi3Config, PhimoeConfig, PLBartConfig, ProphetNetConfig, QDQBertConfig, Qwen2Config, Qwen2MoeConfig, RecurrentGemmaConfig, ReformerConfig, RemBertConfig, RobertaConfig, RobertaPreLayerNormConfig, RoCBertConfig, RoFormerConfig, RwkvConfig, Speech2Text2Config, StableLmConfig, Starcoder2Config, TransfoXLConfig, TrOCRConfig, WhisperConfig, XGLMConfig, XLMConfig, XLMProphetNetConfig, XLMRobertaConfig, XLMRobertaXLConfig, XLNetConfig, XmodConfig, ZambaConfig."
     ]
    }
   ],
   "source": [
    "from langchain.llms import HuggingFaceHub\n",
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.vectorstores import Chroma\n",
    "from langchain.document_loaders import PyPDFLoader\n",
    "from langchain.chains import RetrievalQA\n",
    "from langchain_huggingface import HuggingFaceEndpoint\n",
    "\n",
    "from langchain_huggingface import HuggingFacePipeline\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer, pipeline\n",
    "\n",
    "llm = HuggingFacePipeline.from_model_id(\n",
    "    model_id=\"google/flan-t5-small\",\n",
    "    task=\"text-generation\",\n",
    "    pipeline_kwargs={\"max_new_tokens\": 10},\n",
    ")\n",
    "\n",
    "import gradio as gr\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "# Set Hugging Face API Token (Replace with your actual token)\n",
    "os.environ[\"HUGGINGFACEHUB_API_TOKEN\"] = os.getenv(\"HUGGINGFACEHUB_API_TOKEN\")\n",
    "\n",
    "# Suppress warnings\n",
    "def warn(*args, **kwargs):\n",
    "    pass\n",
    "\n",
    "import warnings\n",
    "warnings.warn = warn\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "## LLM using Hugging Face\n",
    "def get_llm():\n",
    "    llm = llm\n",
    "    return llm\n",
    "\n",
    "## Document loader with debugging\n",
    "def document_loader(file):\n",
    "    loader = PyPDFLoader(file.name)\n",
    "    docs = loader.load_and_split()\n",
    "    for doc in docs:\n",
    "        print(doc.page_content)\n",
    "    return docs\n",
    "\n",
    "\n",
    "## Text splitter with debugging\n",
    "def text_splitter(data):\n",
    "    text_splitter = RecursiveCharacterTextSplitter(\n",
    "        chunk_size=500,\n",
    "        chunk_overlap=50,\n",
    "        length_function=len,\n",
    "    )\n",
    "    chunks = text_splitter.split_documents(data)\n",
    "    if not chunks:\n",
    "        raise ValueError(\"Text splitting failed: No chunks were created from the document.\")\n",
    "    print(f\"Generated {len(chunks)} text chunks.\")\n",
    "    return chunks\n",
    "\n",
    "## Embedding model using Hugging Face\n",
    "def huggingface_embedding():\n",
    "    embedding_model = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-MiniLM-L6-v2\")\n",
    "    return embedding_model\n",
    "\n",
    "## Vector database with debugging\n",
    "def vector_database(chunks):\n",
    "    embedding_model = huggingface_embedding()\n",
    "    vectordb = Chroma.from_documents(chunks, embedding_model,persist_directory=\"./chroma_db\")\n",
    "    vectordb.persist()\n",
    "    print(\"Vector database created successfully.\")\n",
    "    return vectordb\n",
    "\n",
    "## Retriever with debugging\n",
    "def retriever(file):\n",
    "    splits = document_loader(file)\n",
    "    chunks = text_splitter(splits)\n",
    "    vectordb = vector_database(chunks)\n",
    "    retriever = vectordb.as_retriever()\n",
    "    return retriever\n",
    "\n",
    "## QA Chain\n",
    "def retriever_qa(file, query):\n",
    "    llm = get_llm()\n",
    "    retriever_obj = retriever(file)\n",
    "    qa = RetrievalQA.from_chain_type(llm=llm, \n",
    "                                     chain_type=\"stuff\", \n",
    "                                     retriever=retriever_obj, \n",
    "                                     return_source_documents=False)\n",
    "    response = qa.invoke(query)\n",
    "    return response['result']\n",
    "\n",
    "# Create Gradio interface\n",
    "rag_application = gr.Interface(\n",
    "    fn=retriever_qa,\n",
    "    allow_flagging=\"never\",\n",
    "    inputs=[\n",
    "        gr.File(label=\"Upload PDF File\", file_count=\"single\", file_types=['.pdf'], type=\"filepath\"),  # Drag and drop file upload\n",
    "        gr.Textbox(label=\"Input Query\", lines=2, placeholder=\"Type your question here...\")\n",
    "    ],\n",
    "    outputs=gr.Textbox(label=\"Output\"),\n",
    "    title=\"RAG Chatbot\",\n",
    "    description=\"Upload a PDF document and ask any question. The chatbot will try to answer using the provided document.\"\n",
    ")\n",
    "\n",
    "# Launch the app\n",
    "rag_application.launch(server_name=\"0.0.0.0\", server_port=7860)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting chromadb\n",
      "  Using cached chromadb-0.6.3-py3-none-any.whl.metadata (6.8 kB)\n",
      "Requirement already satisfied: build>=1.0.3 in /home/kronos/.local/lib/python3.12/site-packages (from chromadb) (1.2.2.post1)\n",
      "Requirement already satisfied: pydantic>=1.9 in /home/kronos/anaconda3/envs/rapids-24.12/lib/python3.12/site-packages (from chromadb) (2.10.6)\n",
      "Collecting chroma-hnswlib==0.7.6 (from chromadb)\n",
      "  Using cached chroma_hnswlib-0.7.6-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (252 bytes)\n",
      "Requirement already satisfied: fastapi>=0.95.2 in /home/kronos/.local/lib/python3.12/site-packages (from chromadb) (0.115.7)\n",
      "Requirement already satisfied: uvicorn>=0.18.3 in /home/kronos/.local/lib/python3.12/site-packages (from uvicorn[standard]>=0.18.3->chromadb) (0.34.0)\n",
      "Requirement already satisfied: numpy>=1.22.5 in /home/kronos/anaconda3/envs/rapids-24.12/lib/python3.12/site-packages (from chromadb) (1.26.4)\n",
      "Collecting posthog>=2.4.0 (from chromadb)\n",
      "  Downloading posthog-3.11.0-py2.py3-none-any.whl.metadata (2.9 kB)\n",
      "Requirement already satisfied: typing_extensions>=4.5.0 in /home/kronos/anaconda3/envs/rapids-24.12/lib/python3.12/site-packages (from chromadb) (4.12.2)\n",
      "Requirement already satisfied: onnxruntime>=1.14.1 in /home/kronos/.local/lib/python3.12/site-packages (from chromadb) (1.20.1)\n",
      "Requirement already satisfied: opentelemetry-api>=1.2.0 in /home/kronos/.local/lib/python3.12/site-packages (from chromadb) (1.29.0)\n",
      "Requirement already satisfied: opentelemetry-exporter-otlp-proto-grpc>=1.2.0 in /home/kronos/.local/lib/python3.12/site-packages (from chromadb) (1.29.0)\n",
      "Requirement already satisfied: opentelemetry-instrumentation-fastapi>=0.41b0 in /home/kronos/.local/lib/python3.12/site-packages (from chromadb) (0.50b0)\n",
      "Requirement already satisfied: opentelemetry-sdk>=1.2.0 in /home/kronos/.local/lib/python3.12/site-packages (from chromadb) (1.29.0)\n",
      "Requirement already satisfied: tokenizers>=0.13.2 in /home/kronos/anaconda3/envs/rapids-24.12/lib/python3.12/site-packages (from chromadb) (0.21.0)\n",
      "Requirement already satisfied: pypika>=0.48.9 in /home/kronos/.local/lib/python3.12/site-packages (from chromadb) (0.48.9)\n",
      "Requirement already satisfied: tqdm>=4.65.0 in /home/kronos/anaconda3/envs/rapids-24.12/lib/python3.12/site-packages (from chromadb) (4.67.1)\n",
      "Requirement already satisfied: overrides>=7.3.1 in /home/kronos/.local/lib/python3.12/site-packages (from chromadb) (7.7.0)\n",
      "Requirement already satisfied: importlib-resources in /home/kronos/.local/lib/python3.12/site-packages (from chromadb) (6.5.2)\n",
      "Requirement already satisfied: grpcio>=1.58.0 in /home/kronos/.local/lib/python3.12/site-packages (from chromadb) (1.69.0)\n",
      "Requirement already satisfied: bcrypt>=4.0.1 in /home/kronos/.local/lib/python3.12/site-packages (from chromadb) (4.2.1)\n",
      "Requirement already satisfied: typer>=0.9.0 in /home/kronos/anaconda3/envs/rapids-24.12/lib/python3.12/site-packages (from chromadb) (0.15.1)\n",
      "Requirement already satisfied: kubernetes>=28.1.0 in /home/kronos/.local/lib/python3.12/site-packages (from chromadb) (31.0.0)\n",
      "Requirement already satisfied: tenacity>=8.2.3 in /home/kronos/.local/lib/python3.12/site-packages (from chromadb) (8.5.0)\n",
      "Requirement already satisfied: PyYAML>=6.0.0 in /home/kronos/anaconda3/envs/rapids-24.12/lib/python3.12/site-packages (from chromadb) (6.0.2)\n",
      "Requirement already satisfied: mmh3>=4.0.1 in /home/kronos/.local/lib/python3.12/site-packages (from chromadb) (5.0.1)\n",
      "Requirement already satisfied: orjson>=3.9.12 in /home/kronos/anaconda3/envs/rapids-24.12/lib/python3.12/site-packages (from chromadb) (3.10.15)\n",
      "Requirement already satisfied: httpx>=0.27.0 in /home/kronos/anaconda3/envs/rapids-24.12/lib/python3.12/site-packages (from chromadb) (0.28.1)\n",
      "Requirement already satisfied: rich>=10.11.0 in /home/kronos/anaconda3/envs/rapids-24.12/lib/python3.12/site-packages (from chromadb) (13.9.4)\n",
      "Requirement already satisfied: packaging>=19.1 in /home/kronos/.local/lib/python3.12/site-packages (from build>=1.0.3->chromadb) (23.2)\n",
      "Requirement already satisfied: pyproject_hooks in /home/kronos/.local/lib/python3.12/site-packages (from build>=1.0.3->chromadb) (1.2.0)\n",
      "Requirement already satisfied: starlette<0.46.0,>=0.40.0 in /home/kronos/.local/lib/python3.12/site-packages (from fastapi>=0.95.2->chromadb) (0.45.2)\n",
      "Requirement already satisfied: anyio in /home/kronos/anaconda3/envs/rapids-24.12/lib/python3.12/site-packages (from httpx>=0.27.0->chromadb) (4.8.0)\n",
      "Requirement already satisfied: certifi in /home/kronos/anaconda3/envs/rapids-24.12/lib/python3.12/site-packages (from httpx>=0.27.0->chromadb) (2025.1.31)\n",
      "Requirement already satisfied: httpcore==1.* in /home/kronos/anaconda3/envs/rapids-24.12/lib/python3.12/site-packages (from httpx>=0.27.0->chromadb) (1.0.7)\n",
      "Requirement already satisfied: idna in /home/kronos/anaconda3/envs/rapids-24.12/lib/python3.12/site-packages (from httpx>=0.27.0->chromadb) (3.10)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /home/kronos/anaconda3/envs/rapids-24.12/lib/python3.12/site-packages (from httpcore==1.*->httpx>=0.27.0->chromadb) (0.14.0)\n",
      "Requirement already satisfied: six>=1.9.0 in /home/kronos/anaconda3/envs/rapids-24.12/lib/python3.12/site-packages (from kubernetes>=28.1.0->chromadb) (1.17.0)\n",
      "Requirement already satisfied: python-dateutil>=2.5.3 in /home/kronos/anaconda3/envs/rapids-24.12/lib/python3.12/site-packages (from kubernetes>=28.1.0->chromadb) (2.9.0.post0)\n",
      "Requirement already satisfied: google-auth>=1.0.1 in /home/kronos/.local/lib/python3.12/site-packages (from kubernetes>=28.1.0->chromadb) (2.38.0)\n",
      "Requirement already satisfied: websocket-client!=0.40.0,!=0.41.*,!=0.42.*,>=0.32.0 in /home/kronos/.local/lib/python3.12/site-packages (from kubernetes>=28.1.0->chromadb) (1.8.0)\n",
      "Requirement already satisfied: requests in /home/kronos/.local/lib/python3.12/site-packages (from kubernetes>=28.1.0->chromadb) (2.32.2)\n",
      "Requirement already satisfied: requests-oauthlib in /home/kronos/.local/lib/python3.12/site-packages (from kubernetes>=28.1.0->chromadb) (2.0.0)\n",
      "Requirement already satisfied: oauthlib>=3.2.2 in /home/kronos/.local/lib/python3.12/site-packages (from kubernetes>=28.1.0->chromadb) (3.2.2)\n",
      "Requirement already satisfied: urllib3>=1.24.2 in /home/kronos/anaconda3/envs/rapids-24.12/lib/python3.12/site-packages (from kubernetes>=28.1.0->chromadb) (2.3.0)\n",
      "Requirement already satisfied: durationpy>=0.7 in /home/kronos/.local/lib/python3.12/site-packages (from kubernetes>=28.1.0->chromadb) (0.9)\n",
      "Requirement already satisfied: coloredlogs in /home/kronos/.local/lib/python3.12/site-packages (from onnxruntime>=1.14.1->chromadb) (15.0.1)\n",
      "Requirement already satisfied: flatbuffers in /home/kronos/.local/lib/python3.12/site-packages (from onnxruntime>=1.14.1->chromadb) (25.1.21)\n",
      "Requirement already satisfied: protobuf in /home/kronos/anaconda3/envs/rapids-24.12/lib/python3.12/site-packages (from onnxruntime>=1.14.1->chromadb) (4.25.3)\n",
      "Requirement already satisfied: sympy in /home/kronos/anaconda3/envs/rapids-24.12/lib/python3.12/site-packages (from onnxruntime>=1.14.1->chromadb) (1.13.3)\n",
      "Requirement already satisfied: deprecated>=1.2.6 in /home/kronos/.local/lib/python3.12/site-packages (from opentelemetry-api>=1.2.0->chromadb) (1.2.15)\n",
      "Collecting importlib-metadata<=8.5.0,>=6.0 (from opentelemetry-api>=1.2.0->chromadb)\n",
      "  Downloading importlib_metadata-8.5.0-py3-none-any.whl.metadata (4.8 kB)\n",
      "Requirement already satisfied: googleapis-common-protos~=1.52 in /home/kronos/.local/lib/python3.12/site-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb) (1.66.0)\n",
      "Requirement already satisfied: opentelemetry-exporter-otlp-proto-common==1.29.0 in /home/kronos/.local/lib/python3.12/site-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb) (1.29.0)\n",
      "Requirement already satisfied: opentelemetry-proto==1.29.0 in /home/kronos/.local/lib/python3.12/site-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb) (1.29.0)\n",
      "Collecting protobuf (from onnxruntime>=1.14.1->chromadb)\n",
      "  Downloading protobuf-5.29.3-cp38-abi3-manylinux2014_x86_64.whl.metadata (592 bytes)\n",
      "Requirement already satisfied: opentelemetry-instrumentation-asgi==0.50b0 in /home/kronos/.local/lib/python3.12/site-packages (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb) (0.50b0)\n",
      "Requirement already satisfied: opentelemetry-instrumentation==0.50b0 in /home/kronos/.local/lib/python3.12/site-packages (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb) (0.50b0)\n",
      "Requirement already satisfied: opentelemetry-semantic-conventions==0.50b0 in /home/kronos/.local/lib/python3.12/site-packages (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb) (0.50b0)\n",
      "Requirement already satisfied: opentelemetry-util-http==0.50b0 in /home/kronos/.local/lib/python3.12/site-packages (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb) (0.50b0)\n",
      "Requirement already satisfied: wrapt<2.0.0,>=1.0.0 in /home/kronos/.local/lib/python3.12/site-packages (from opentelemetry-instrumentation==0.50b0->opentelemetry-instrumentation-fastapi>=0.41b0->chromadb) (1.17.2)\n",
      "Requirement already satisfied: asgiref~=3.0 in /home/kronos/.local/lib/python3.12/site-packages (from opentelemetry-instrumentation-asgi==0.50b0->opentelemetry-instrumentation-fastapi>=0.41b0->chromadb) (3.8.1)\n",
      "Collecting monotonic>=1.5 (from posthog>=2.4.0->chromadb)\n",
      "  Using cached monotonic-1.6-py2.py3-none-any.whl.metadata (1.5 kB)\n",
      "Collecting backoff>=1.10.0 (from posthog>=2.4.0->chromadb)\n",
      "  Using cached backoff-2.2.1-py3-none-any.whl.metadata (14 kB)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /home/kronos/anaconda3/envs/rapids-24.12/lib/python3.12/site-packages (from pydantic>=1.9->chromadb) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.27.2 in /home/kronos/anaconda3/envs/rapids-24.12/lib/python3.12/site-packages (from pydantic>=1.9->chromadb) (2.27.2)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /home/kronos/anaconda3/envs/rapids-24.12/lib/python3.12/site-packages (from rich>=10.11.0->chromadb) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /home/kronos/anaconda3/envs/rapids-24.12/lib/python3.12/site-packages (from rich>=10.11.0->chromadb) (2.19.1)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.16.4 in /home/kronos/anaconda3/envs/rapids-24.12/lib/python3.12/site-packages (from tokenizers>=0.13.2->chromadb) (0.28.1)\n",
      "Requirement already satisfied: click>=8.0.0 in /home/kronos/anaconda3/envs/rapids-24.12/lib/python3.12/site-packages (from typer>=0.9.0->chromadb) (8.1.8)\n",
      "Requirement already satisfied: shellingham>=1.3.0 in /home/kronos/anaconda3/envs/rapids-24.12/lib/python3.12/site-packages (from typer>=0.9.0->chromadb) (1.5.4)\n",
      "Requirement already satisfied: httptools>=0.6.3 in /home/kronos/.local/lib/python3.12/site-packages (from uvicorn[standard]>=0.18.3->chromadb) (0.6.4)\n",
      "Requirement already satisfied: python-dotenv>=0.13 in /home/kronos/anaconda3/envs/rapids-24.12/lib/python3.12/site-packages (from uvicorn[standard]>=0.18.3->chromadb) (1.0.1)\n",
      "Requirement already satisfied: uvloop!=0.15.0,!=0.15.1,>=0.14.0 in /home/kronos/.local/lib/python3.12/site-packages (from uvicorn[standard]>=0.18.3->chromadb) (0.21.0)\n",
      "Requirement already satisfied: watchfiles>=0.13 in /home/kronos/.local/lib/python3.12/site-packages (from uvicorn[standard]>=0.18.3->chromadb) (1.0.4)\n",
      "Requirement already satisfied: websockets>=10.4 in /home/kronos/anaconda3/envs/rapids-24.12/lib/python3.12/site-packages (from uvicorn[standard]>=0.18.3->chromadb) (14.2)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /home/kronos/.local/lib/python3.12/site-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (5.5.1)\n",
      "Collecting pyasn1-modules>=0.2.1 (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb)\n",
      "  Downloading pyasn1_modules-0.4.1-py3-none-any.whl.metadata (3.5 kB)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /home/kronos/.local/lib/python3.12/site-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (4.9)\n",
      "Requirement already satisfied: filelock in /home/kronos/anaconda3/envs/rapids-24.12/lib/python3.12/site-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers>=0.13.2->chromadb) (3.17.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /home/kronos/anaconda3/envs/rapids-24.12/lib/python3.12/site-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers>=0.13.2->chromadb) (2025.2.0)\n",
      "Requirement already satisfied: zipp>=3.20 in /home/kronos/anaconda3/envs/rapids-24.12/lib/python3.12/site-packages (from importlib-metadata<=8.5.0,>=6.0->opentelemetry-api>=1.2.0->chromadb) (3.21.0)\n",
      "Requirement already satisfied: mdurl~=0.1 in /home/kronos/anaconda3/envs/rapids-24.12/lib/python3.12/site-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->chromadb) (0.1.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/kronos/anaconda3/envs/rapids-24.12/lib/python3.12/site-packages (from requests->kubernetes>=28.1.0->chromadb) (3.4.1)\n",
      "Requirement already satisfied: sniffio>=1.1 in /home/kronos/anaconda3/envs/rapids-24.12/lib/python3.12/site-packages (from anyio->httpx>=0.27.0->chromadb) (1.3.1)\n",
      "Requirement already satisfied: humanfriendly>=9.1 in /home/kronos/.local/lib/python3.12/site-packages (from coloredlogs->onnxruntime>=1.14.1->chromadb) (10.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /home/kronos/anaconda3/envs/rapids-24.12/lib/python3.12/site-packages (from sympy->onnxruntime>=1.14.1->chromadb) (1.3.0)\n",
      "Collecting pyasn1<0.7.0,>=0.4.6 (from pyasn1-modules>=0.2.1->google-auth>=1.0.1->kubernetes>=28.1.0->chromadb)\n",
      "  Downloading pyasn1-0.6.1-py3-none-any.whl.metadata (8.4 kB)\n",
      "Using cached chromadb-0.6.3-py3-none-any.whl (611 kB)\n",
      "Using cached chroma_hnswlib-0.7.6-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.4 MB)\n",
      "Downloading posthog-3.11.0-py2.py3-none-any.whl (72 kB)\n",
      "Using cached backoff-2.2.1-py3-none-any.whl (15 kB)\n",
      "Downloading importlib_metadata-8.5.0-py3-none-any.whl (26 kB)\n",
      "Using cached monotonic-1.6-py2.py3-none-any.whl (8.2 kB)\n",
      "Downloading protobuf-5.29.3-cp38-abi3-manylinux2014_x86_64.whl (319 kB)\n",
      "Downloading pyasn1_modules-0.4.1-py3-none-any.whl (181 kB)\n",
      "Downloading pyasn1-0.6.1-py3-none-any.whl (83 kB)\n",
      "Installing collected packages: monotonic, pyasn1, protobuf, importlib-metadata, chroma-hnswlib, backoff, pyasn1-modules, posthog, chromadb\n",
      "  Attempting uninstall: protobuf\n",
      "    Found existing installation: protobuf 4.25.3\n",
      "    Uninstalling protobuf-4.25.3:\n",
      "      Successfully uninstalled protobuf-4.25.3\n",
      "  Attempting uninstall: importlib-metadata\n",
      "    Found existing installation: importlib_metadata 8.6.1\n",
      "    Uninstalling importlib_metadata-8.6.1:\n",
      "      Successfully uninstalled importlib_metadata-8.6.1\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "ibm-watson-machine-learning 1.0.367 requires tabulate, which is not installed.\n",
      "dash 2.18.2 requires dash_core_components==2.0.0, which is not installed.\n",
      "dash 2.18.2 requires dash_html_components==2.0.0, which is not installed.\n",
      "dash 2.18.2 requires dash_table==5.0.0, which is not installed.\n",
      "ibm-watson-machine-learning 1.0.367 requires pandas<2.2.0,>=0.24.2, but you have pandas 2.2.3 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed backoff-2.2.1 chroma-hnswlib-0.7.6 chromadb-0.6.3 importlib-metadata-8.5.0 monotonic-1.6 posthog-3.11.0 protobuf-5.29.3 pyasn1-0.6.1 pyasn1-modules-0.4.1\n"
     ]
    }
   ],
   "source": [
    "!pip install chromadb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Closing server running on port: 7860\n"
     ]
    }
   ],
   "source": [
    "gr.close_all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using the default legacy behaviour of the <class 'transformers.models.t5.tokenization_t5.T5Tokenizer'>. This is expected, and simply means that the `legacy` (previous) behavior will be used so nothing changes for you. If you want to use the new behaviour, set `legacy=False`. This should only be set if you understand what it means, and thoroughly read the reason why this was added as explained in https://github.com/huggingface/transformers/pull/24565\n",
      "2025-02-06 22:34:59.084385: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-02-06 22:34:59.091169: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2025-02-06 22:34:59.096786: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2025-02-06 22:34:59.098551: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2025-02-06 22:34:59.103807: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: SSE4.1 SSE4.2 AVX AVX2 AVX512F AVX512_VNNI AVX512_BF16 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<extra_id_0>\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForSeq2SeqLM, AutoTokenizer\n",
    "\n",
    "model_id = \"google/mt5-small\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_id)\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(model_id)\n",
    "\n",
    "input_text = \"Translate English to French: Hello, how are you?\"\n",
    "input_ids = tokenizer(input_text, return_tensors=\"pt\").input_ids\n",
    "outputs = model.generate(input_ids)\n",
    "print(tokenizer.decode(outputs[0], skip_special_tokens=True))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: python-dotenv in /home/kronos/anaconda3/envs/pytorch_env/lib/python3.12/site-packages (1.0.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install python-dotenv\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def document_loader(file):\n",
    "    loader = PyPDFLoader(file)\n",
    "    for page in loader.load_and_split():\n",
    "        return page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "print(document_loader(\"/home/kronos/Desktop/UAI.pdf\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.document_loaders import PyPDFLoader\n",
    "loader = PyPDFLoader(\"/home/kronos/Desktop/hindu.pdf\")\n",
    "pages = loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "22"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(pages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "page = pages[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AHY-HYE CM\n",
      "YK\n",
      "WEDNESDAY\n",
      "January 29, 2025\n",
      "HYDERABAD\n",
      "CITY EDITION\n",
      "18 Pages /uni20B9 8.00www.thehindu.com\n",
      "Printed at » Chennai» Coimbatore » Bengaluru » Hyderabad » Madurai» Noida» Visakhapatnam » Thiruvananthapuram » Kochi» Vijayawada » Mangaluru » Tiruchirapalli » Kolkata» Hubballi» Mohali» Malappuram » Mumbai» Tirupati» Lucknow » Cuttack» PatnaVol. 50 /L50539No. 24https://newsth.live/fb\n",
      "https://newsth.live/x\n",
      "https://newsth.live/ig\n",
      "RNI No. TELENG/1976/49963\n",
      "‘Good policies\n",
      "drew companies’ \n",
      "HYDERABAD\n",
      "Chief Minister A. Revanth\n",
      "Reddy has asserted that\n",
      "several global majors came\n",
      "forward to sign MoUs with the\n",
      "State government at Davos\n",
      "because of the progressive\n",
      "policies that have been put in\n",
      "place by the Congress\n",
      "government. »Page 6\n",
      "Skyhigh airfares\n",
      "to Maha Kumbh\n",
      "HYDERABAD\n",
      "Pilgrimage to Maha Kumbh\n",
      "Mela in Prayagraj from\n",
      "Hyderabad has been\n",
      "overshadowed by exorbitant\n",
      "airfares, with prices ranging up\n",
      "to /uni20B91.02 lakh per person for a\n",
      "one-way journey. »Page 4NEARBY\n",
      "/L50301\n",
      "MISRI VISIT\n",
      "Had frank talks on\n",
      "issues, says China\n",
      "NEWS»PAGE 12\n",
      "NEW MILESTONE\n",
      "Countdown to ISRO’s\n",
      "100th mission begins\n",
      "NEWS»PAGE 12\n",
      "BEST OF THE BEST\n",
      "Bumrah named ICC\n",
      "Cricketer of the Year\n",
      "SPORT»PAGE 15\n",
      "Prime Minister Na-\n",
      "rendra Modi is like-\n",
      "ly to visit Washing-\n",
      "ton DC in February, U.S.\n",
      "President Donald Trump\n",
      "has said. \n",
      "In an announcement\n",
      "that came hours after Mr.\n",
      "Trump and Mr. Modi spoke\n",
      "over the phone on Mon-\n",
      "day, the White House\n",
      "called for a “fair bilateral\n",
      "trading relationship”, and\n",
      "indicated that India would\n",
      "host the leaders of the Qua-\n",
      "drilateral grouping in the\n",
      "coming months.\n",
      "“The two leaders dis-\n",
      "cussed expanding and dee-\n",
      "pening cooperation. They\n",
      "also discussed a range of\n",
      "regional issues, including\n",
      "security in the Indo-Pacif-\n",
      "ic, the Middle East, and Eu-\n",
      "rope. The President em-phasised the importance\n",
      "of increasing its procure-\n",
      "ment of America-made se-\n",
      "curity equipment and\n",
      "moving toward a fair bilat-\n",
      "eral trading relationship,”\n",
      "the White House statement\n",
      "said. \n",
      "“The leaders discussed\n",
      "plans for Mr. Modi to visit\n",
      "the White House, under-scoring the strength of the\n",
      "friendship and strategic\n",
      "ties between our nations.\n",
      "Both leaders emphasised\n",
      "their commitment to ad-\n",
      "vance the U.S.-India stra-\n",
      "tegic partnership and the\n",
      "Indo-Paci/f_ic Quad partner-\n",
      "ship, with India hosting\n",
      "Quad leaders for the /f_irst\n",
      "time later this year,” thepress note said.\n",
      "Mr. Modi on Monday\n",
      "said he had a telephone\n",
      "conversation with Mr.\n",
      "Trump and had agreed to\n",
      "work for “global peace”\n",
      "and “security”. “Congratu-\n",
      "lated him [Mr. Trump] on\n",
      "his historic second term.\n",
      "We are committed to a mu-\n",
      "tually bene/f_icial and trust-\n",
      "ed partnership, ” the Prime\n",
      "Minister said. However,\n",
      "President Trump added a\n",
      "new dimension to the rela-\n",
      "tionship soon after holding\n",
      "the telephone call with Mr.\n",
      "Modi, with the call for put-\n",
      "ting “America /f_irst” in\n",
      "trade relation with major\n",
      "economies. “We are going\n",
      "to put tariﬀs on outside\n",
      "countries , ” Mr. Trump told\n",
      "agathering of House Repu-\n",
      "blicans in Florida.Modi likely to visit U.S. to\n",
      "deepen ties, says Trump\n",
      "Coming closer: The White House says the two leaders discussed\n",
      "expanding and deepening cooperation. REUTERSU.S. President, however, adds a new dimension to the r elationship soon after a telephone call \n",
      "with the Prime Minister, calling for putting ‘ America  /f_irst’ in trade relations with major economies\n",
      "Kallol Bhattacherjee\n",
      "NEW DELHI\n",
      "CONTINUED ON\n",
      "»PAGE 10TUNGSTEN BLOCK\n",
      "The dynamics of\n",
      "mining politics \n",
      "Need for the metal must\n",
      "be balanced against\n",
      "ecological concerns\n",
      "EDITORIAL»PAGE 8\n",
      "ASER STUDY\n",
      "Learning\n",
      "registers\n",
      "post-COVID\n",
      "level recovery\n",
      "NEWS»PAGE 10\n",
      "OPPORTUNITIES»PAGE 5Anew player in the arti/f_i-\n",
      "cial intelligence (AI) race,\n",
      "the Chinese start-up Deep-\n",
      "Seek, has created a buzz in\n",
      "global tech circles with the\n",
      "launch of its cutting-edge\n",
      "AI models, claiming they\n",
      "nearly match the capabili-\n",
      "ties of top industry leaders\n",
      "in the U.S. — all while being\n",
      "far more aﬀordable. The\n",
      "company’s AI model,\n",
      "DeepSeek-R1, has ignited a\n",
      "fresh debate over the shift-\n",
      "ing dynamics of the global\n",
      "AI market.\n",
      "Monday night’s trading\n",
      "session on Wall Street left\n",
      "Big Tech companies reel-\n",
      "ing as investors scrambled\n",
      "to make sense of the dam-\n",
      "age. AI chip maker Nvidia’s\n",
      "market value declined by\n",
      "half a trillion dollars in the\n",
      "biggest single-session loss\n",
      "for any company ever.DeepSeek AI\n",
      "model jolts\n",
      "global tech\n",
      "landscape\n",
      "John Xavier\n",
      "CHENNAI\n",
      "CONTINUED ON\n",
      "»PAGE 10Family members of ﬁshermen from Karaikal express ang uish over\n",
      "the attack by the Sri Lankan Navy on their kin on Tu esday. PTI\n",
      "ASri Lankan Navy patrol\n",
      "/f_ired at a /f_ishing boat from\n",
      "Karaikal in Puducherry in\n",
      "the early hours of Tuesday,\n",
      "causing “serious injuries”\n",
      "to two /f_ishermen. The Sri\n",
      "Lankan Navy also arrested\n",
      "13 /f_ishermen from Tamil\n",
      "Nadu and Puducherry\n",
      "aboard the boat, on charg-\n",
      "es of trespassing and /f_ish-\n",
      "ing in the island nation’s\n",
      "waters.\n",
      "While India lodged a“strong protest”, Sri Lanka\n",
      "claimed that the Indian\n",
      "/f_ishermen were illegally\n",
      "/f_ishing in its territorial wa-\n",
      "ters and had attempted to\n",
      "“assault” its naval oﬃcers,\n",
      "adding that two /f_ishermen\n",
      "received “slight injuries” in\n",
      "“accidental /f_ire”.\n",
      "India’s Ministry of Exter-\n",
      "nal Aﬀairs said two /f_isher-\n",
      "men suﬀered “serious inju-\n",
      "ries” and were receiving\n",
      "treatment at the Jaﬀna\n",
      "Teaching Hospital. Sri Lankan Navy /f_ires\n",
      "at Indian boat, two\n",
      "/f_ishermen injured\n",
      "Meera Srinivasan\n",
      "R. Rajaram\n",
      "COLOMBO/TIRUCHI\n",
      "CONTINUED ON\n",
      "»PAGE 10c9597d19-0272-4afc-b850-ed6b205b3372\n",
      "c9597d19-0272-4afc-b850-ed6b205b3372\n"
     ]
    }
   ],
   "source": [
    "print(page.page_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'source': '/home/kronos/Desktop/hindu.pdf', 'page': 0}"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "page.metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Document(metadata={'source': '/home/kronos/Desktop/UAI.pdf', 'page': 0}, page_content='')"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.llms import HuggingFaceHub\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting llama-index\n",
      "  Downloading llama_index-0.12.16-py3-none-any.whl.metadata (12 kB)\n",
      "Collecting llama-index-agent-openai<0.5.0,>=0.4.0 (from llama-index)\n",
      "  Downloading llama_index_agent_openai-0.4.5-py3-none-any.whl.metadata (727 bytes)\n",
      "Collecting llama-index-cli<0.5.0,>=0.4.0 (from llama-index)\n",
      "  Downloading llama_index_cli-0.4.0-py3-none-any.whl.metadata (1.5 kB)\n",
      "Collecting llama-index-core<0.13.0,>=0.12.16 (from llama-index)\n",
      "  Downloading llama_index_core-0.12.16.post1-py3-none-any.whl.metadata (2.5 kB)\n",
      "Collecting llama-index-embeddings-openai<0.4.0,>=0.3.0 (from llama-index)\n",
      "  Downloading llama_index_embeddings_openai-0.3.1-py3-none-any.whl.metadata (684 bytes)\n",
      "Collecting llama-index-indices-managed-llama-cloud>=0.4.0 (from llama-index)\n",
      "  Downloading llama_index_indices_managed_llama_cloud-0.6.4-py3-none-any.whl.metadata (3.6 kB)\n",
      "Collecting llama-index-llms-openai<0.4.0,>=0.3.0 (from llama-index)\n",
      "  Downloading llama_index_llms_openai-0.3.18-py3-none-any.whl.metadata (3.3 kB)\n",
      "Collecting llama-index-multi-modal-llms-openai<0.5.0,>=0.4.0 (from llama-index)\n",
      "  Downloading llama_index_multi_modal_llms_openai-0.4.3-py3-none-any.whl.metadata (726 bytes)\n",
      "Collecting llama-index-program-openai<0.4.0,>=0.3.0 (from llama-index)\n",
      "  Downloading llama_index_program_openai-0.3.1-py3-none-any.whl.metadata (764 bytes)\n",
      "Collecting llama-index-question-gen-openai<0.4.0,>=0.3.0 (from llama-index)\n",
      "  Downloading llama_index_question_gen_openai-0.3.0-py3-none-any.whl.metadata (783 bytes)\n",
      "Collecting llama-index-readers-file<0.5.0,>=0.4.0 (from llama-index)\n",
      "  Downloading llama_index_readers_file-0.4.4-py3-none-any.whl.metadata (5.4 kB)\n",
      "Collecting llama-index-readers-llama-parse>=0.4.0 (from llama-index)\n",
      "  Downloading llama_index_readers_llama_parse-0.4.0-py3-none-any.whl.metadata (3.6 kB)\n",
      "Requirement already satisfied: nltk>3.8.1 in /home/kronos/anaconda3/envs/rapids-24.12/lib/python3.12/site-packages (from llama-index) (3.9.1)\n",
      "Collecting openai>=1.14.0 (from llama-index-agent-openai<0.5.0,>=0.4.0->llama-index)\n",
      "  Downloading openai-1.61.1-py3-none-any.whl.metadata (27 kB)\n",
      "Requirement already satisfied: PyYAML>=6.0.1 in /home/kronos/anaconda3/envs/rapids-24.12/lib/python3.12/site-packages (from llama-index-core<0.13.0,>=0.12.16->llama-index) (6.0.2)\n",
      "Requirement already satisfied: SQLAlchemy>=1.4.49 in /home/kronos/anaconda3/envs/rapids-24.12/lib/python3.12/site-packages (from SQLAlchemy[asyncio]>=1.4.49->llama-index-core<0.13.0,>=0.12.16->llama-index) (2.0.37)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.6 in /home/kronos/anaconda3/envs/rapids-24.12/lib/python3.12/site-packages (from llama-index-core<0.13.0,>=0.12.16->llama-index) (3.11.12)\n",
      "Requirement already satisfied: dataclasses-json in /home/kronos/anaconda3/envs/rapids-24.12/lib/python3.12/site-packages (from llama-index-core<0.13.0,>=0.12.16->llama-index) (0.6.7)\n",
      "Requirement already satisfied: deprecated>=1.2.9.3 in /home/kronos/.local/lib/python3.12/site-packages (from llama-index-core<0.13.0,>=0.12.16->llama-index) (1.2.15)\n",
      "Collecting dirtyjson<2.0.0,>=1.0.8 (from llama-index-core<0.13.0,>=0.12.16->llama-index)\n",
      "  Downloading dirtyjson-1.0.8-py3-none-any.whl.metadata (11 kB)\n",
      "Collecting filetype<2.0.0,>=1.2.0 (from llama-index-core<0.13.0,>=0.12.16->llama-index)\n",
      "  Downloading filetype-1.2.0-py2.py3-none-any.whl.metadata (6.5 kB)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /home/kronos/anaconda3/envs/rapids-24.12/lib/python3.12/site-packages (from llama-index-core<0.13.0,>=0.12.16->llama-index) (2025.2.0)\n",
      "Requirement already satisfied: httpx in /home/kronos/anaconda3/envs/rapids-24.12/lib/python3.12/site-packages (from llama-index-core<0.13.0,>=0.12.16->llama-index) (0.28.1)\n",
      "Requirement already satisfied: nest-asyncio<2.0.0,>=1.5.8 in /home/kronos/anaconda3/envs/rapids-24.12/lib/python3.12/site-packages (from llama-index-core<0.13.0,>=0.12.16->llama-index) (1.6.0)\n",
      "Requirement already satisfied: networkx>=3.0 in /home/kronos/anaconda3/envs/rapids-24.12/lib/python3.12/site-packages (from llama-index-core<0.13.0,>=0.12.16->llama-index) (3.4.2)\n",
      "Requirement already satisfied: numpy in /home/kronos/anaconda3/envs/rapids-24.12/lib/python3.12/site-packages (from llama-index-core<0.13.0,>=0.12.16->llama-index) (1.26.4)\n",
      "Requirement already satisfied: pillow>=9.0.0 in /home/kronos/anaconda3/envs/rapids-24.12/lib/python3.12/site-packages (from llama-index-core<0.13.0,>=0.12.16->llama-index) (11.1.0)\n",
      "Requirement already satisfied: pydantic>=2.8.0 in /home/kronos/anaconda3/envs/rapids-24.12/lib/python3.12/site-packages (from llama-index-core<0.13.0,>=0.12.16->llama-index) (2.10.6)\n",
      "Requirement already satisfied: requests>=2.31.0 in /home/kronos/.local/lib/python3.12/site-packages (from llama-index-core<0.13.0,>=0.12.16->llama-index) (2.32.2)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.2.0 in /home/kronos/.local/lib/python3.12/site-packages (from llama-index-core<0.13.0,>=0.12.16->llama-index) (8.5.0)\n",
      "Collecting tiktoken>=0.3.3 (from llama-index-core<0.13.0,>=0.12.16->llama-index)\n",
      "  Downloading tiktoken-0.8.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.6 kB)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.66.1 in /home/kronos/anaconda3/envs/rapids-24.12/lib/python3.12/site-packages (from llama-index-core<0.13.0,>=0.12.16->llama-index) (4.67.1)\n",
      "Requirement already satisfied: typing-extensions>=4.5.0 in /home/kronos/anaconda3/envs/rapids-24.12/lib/python3.12/site-packages (from llama-index-core<0.13.0,>=0.12.16->llama-index) (4.12.2)\n",
      "Requirement already satisfied: typing-inspect>=0.8.0 in /home/kronos/anaconda3/envs/rapids-24.12/lib/python3.12/site-packages (from llama-index-core<0.13.0,>=0.12.16->llama-index) (0.9.0)\n",
      "Requirement already satisfied: wrapt in /home/kronos/.local/lib/python3.12/site-packages (from llama-index-core<0.13.0,>=0.12.16->llama-index) (1.17.2)\n",
      "Collecting llama-cloud<0.2.0,>=0.1.8 (from llama-index-indices-managed-llama-cloud>=0.4.0->llama-index)\n",
      "  Downloading llama_cloud-0.1.12-py3-none-any.whl.metadata (851 bytes)\n",
      "Requirement already satisfied: beautifulsoup4<5.0.0,>=4.12.3 in /home/kronos/anaconda3/envs/rapids-24.12/lib/python3.12/site-packages (from llama-index-readers-file<0.5.0,>=0.4.0->llama-index) (4.13.3)\n",
      "Requirement already satisfied: pandas in /home/kronos/anaconda3/envs/rapids-24.12/lib/python3.12/site-packages (from llama-index-readers-file<0.5.0,>=0.4.0->llama-index) (2.2.3)\n",
      "Requirement already satisfied: pypdf<6.0.0,>=5.1.0 in /home/kronos/anaconda3/envs/rapids-24.12/lib/python3.12/site-packages (from llama-index-readers-file<0.5.0,>=0.4.0->llama-index) (5.2.0)\n",
      "Collecting striprtf<0.0.27,>=0.0.26 (from llama-index-readers-file<0.5.0,>=0.4.0->llama-index)\n",
      "  Downloading striprtf-0.0.26-py3-none-any.whl.metadata (2.1 kB)\n",
      "Collecting llama-parse>=0.5.0 (from llama-index-readers-llama-parse>=0.4.0->llama-index)\n",
      "  Downloading llama_parse-0.6.0-py3-none-any.whl.metadata (6.8 kB)\n",
      "Requirement already satisfied: click in /home/kronos/anaconda3/envs/rapids-24.12/lib/python3.12/site-packages (from nltk>3.8.1->llama-index) (8.1.8)\n",
      "Requirement already satisfied: joblib in /home/kronos/anaconda3/envs/rapids-24.12/lib/python3.12/site-packages (from nltk>3.8.1->llama-index) (1.4.2)\n",
      "Requirement already satisfied: regex>=2021.8.3 in /home/kronos/anaconda3/envs/rapids-24.12/lib/python3.12/site-packages (from nltk>3.8.1->llama-index) (2024.11.6)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /home/kronos/anaconda3/envs/rapids-24.12/lib/python3.12/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.13.0,>=0.12.16->llama-index) (2.4.4)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /home/kronos/anaconda3/envs/rapids-24.12/lib/python3.12/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.13.0,>=0.12.16->llama-index) (1.3.2)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /home/kronos/anaconda3/envs/rapids-24.12/lib/python3.12/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.13.0,>=0.12.16->llama-index) (25.1.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /home/kronos/anaconda3/envs/rapids-24.12/lib/python3.12/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.13.0,>=0.12.16->llama-index) (1.5.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /home/kronos/anaconda3/envs/rapids-24.12/lib/python3.12/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.13.0,>=0.12.16->llama-index) (6.1.0)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /home/kronos/anaconda3/envs/rapids-24.12/lib/python3.12/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.13.0,>=0.12.16->llama-index) (0.2.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /home/kronos/anaconda3/envs/rapids-24.12/lib/python3.12/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.13.0,>=0.12.16->llama-index) (1.18.3)\n",
      "Requirement already satisfied: soupsieve>1.2 in /home/kronos/anaconda3/envs/rapids-24.12/lib/python3.12/site-packages (from beautifulsoup4<5.0.0,>=4.12.3->llama-index-readers-file<0.5.0,>=0.4.0->llama-index) (2.5)\n",
      "Requirement already satisfied: certifi>=2024.7.4 in /home/kronos/anaconda3/envs/rapids-24.12/lib/python3.12/site-packages (from llama-cloud<0.2.0,>=0.1.8->llama-index-indices-managed-llama-cloud>=0.4.0->llama-index) (2025.1.31)\n",
      "Requirement already satisfied: anyio in /home/kronos/anaconda3/envs/rapids-24.12/lib/python3.12/site-packages (from httpx->llama-index-core<0.13.0,>=0.12.16->llama-index) (4.8.0)\n",
      "Requirement already satisfied: httpcore==1.* in /home/kronos/anaconda3/envs/rapids-24.12/lib/python3.12/site-packages (from httpx->llama-index-core<0.13.0,>=0.12.16->llama-index) (1.0.7)\n",
      "Requirement already satisfied: idna in /home/kronos/anaconda3/envs/rapids-24.12/lib/python3.12/site-packages (from httpx->llama-index-core<0.13.0,>=0.12.16->llama-index) (3.10)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /home/kronos/anaconda3/envs/rapids-24.12/lib/python3.12/site-packages (from httpcore==1.*->httpx->llama-index-core<0.13.0,>=0.12.16->llama-index) (0.14.0)\n",
      "Collecting llama-cloud-services (from llama-parse>=0.5.0->llama-index-readers-llama-parse>=0.4.0->llama-index)\n",
      "  Downloading llama_cloud_services-0.6.0-py3-none-any.whl.metadata (2.7 kB)\n",
      "Collecting distro<2,>=1.7.0 (from openai>=1.14.0->llama-index-agent-openai<0.5.0,>=0.4.0->llama-index)\n",
      "  Downloading distro-1.9.0-py3-none-any.whl.metadata (6.8 kB)\n",
      "Collecting jiter<1,>=0.4.0 (from openai>=1.14.0->llama-index-agent-openai<0.5.0,>=0.4.0->llama-index)\n",
      "  Downloading jiter-0.8.2-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.2 kB)\n",
      "Requirement already satisfied: sniffio in /home/kronos/anaconda3/envs/rapids-24.12/lib/python3.12/site-packages (from openai>=1.14.0->llama-index-agent-openai<0.5.0,>=0.4.0->llama-index) (1.3.1)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /home/kronos/anaconda3/envs/rapids-24.12/lib/python3.12/site-packages (from pydantic>=2.8.0->llama-index-core<0.13.0,>=0.12.16->llama-index) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.27.2 in /home/kronos/anaconda3/envs/rapids-24.12/lib/python3.12/site-packages (from pydantic>=2.8.0->llama-index-core<0.13.0,>=0.12.16->llama-index) (2.27.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/kronos/anaconda3/envs/rapids-24.12/lib/python3.12/site-packages (from requests>=2.31.0->llama-index-core<0.13.0,>=0.12.16->llama-index) (3.4.1)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/kronos/anaconda3/envs/rapids-24.12/lib/python3.12/site-packages (from requests>=2.31.0->llama-index-core<0.13.0,>=0.12.16->llama-index) (2.3.0)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in /home/kronos/anaconda3/envs/rapids-24.12/lib/python3.12/site-packages (from SQLAlchemy>=1.4.49->SQLAlchemy[asyncio]>=1.4.49->llama-index-core<0.13.0,>=0.12.16->llama-index) (3.1.1)\n",
      "Requirement already satisfied: mypy_extensions>=0.3.0 in /home/kronos/anaconda3/envs/rapids-24.12/lib/python3.12/site-packages (from typing-inspect>=0.8.0->llama-index-core<0.13.0,>=0.12.16->llama-index) (1.0.0)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /home/kronos/anaconda3/envs/rapids-24.12/lib/python3.12/site-packages (from dataclasses-json->llama-index-core<0.13.0,>=0.12.16->llama-index) (3.26.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /home/kronos/anaconda3/envs/rapids-24.12/lib/python3.12/site-packages (from pandas->llama-index-readers-file<0.5.0,>=0.4.0->llama-index) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /home/kronos/anaconda3/envs/rapids-24.12/lib/python3.12/site-packages (from pandas->llama-index-readers-file<0.5.0,>=0.4.0->llama-index) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /home/kronos/anaconda3/envs/rapids-24.12/lib/python3.12/site-packages (from pandas->llama-index-readers-file<0.5.0,>=0.4.0->llama-index) (2025.1)\n",
      "Requirement already satisfied: packaging>=17.0 in /home/kronos/.local/lib/python3.12/site-packages (from marshmallow<4.0.0,>=3.18.0->dataclasses-json->llama-index-core<0.13.0,>=0.12.16->llama-index) (23.2)\n",
      "Requirement already satisfied: six>=1.5 in /home/kronos/anaconda3/envs/rapids-24.12/lib/python3.12/site-packages (from python-dateutil>=2.8.2->pandas->llama-index-readers-file<0.5.0,>=0.4.0->llama-index) (1.17.0)\n",
      "Requirement already satisfied: python-dotenv<2.0.0,>=1.0.1 in /home/kronos/anaconda3/envs/rapids-24.12/lib/python3.12/site-packages (from llama-cloud-services->llama-parse>=0.5.0->llama-index-readers-llama-parse>=0.4.0->llama-index) (1.0.1)\n",
      "Downloading llama_index-0.12.16-py3-none-any.whl (6.9 kB)\n",
      "Downloading llama_index_agent_openai-0.4.5-py3-none-any.whl (13 kB)\n",
      "Downloading llama_index_cli-0.4.0-py3-none-any.whl (27 kB)\n",
      "Downloading llama_index_core-0.12.16.post1-py3-none-any.whl (1.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m10.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading llama_index_embeddings_openai-0.3.1-py3-none-any.whl (6.2 kB)\n",
      "Downloading llama_index_indices_managed_llama_cloud-0.6.4-py3-none-any.whl (13 kB)\n",
      "Downloading llama_index_llms_openai-0.3.18-py3-none-any.whl (14 kB)\n",
      "Downloading llama_index_multi_modal_llms_openai-0.4.3-py3-none-any.whl (5.9 kB)\n",
      "Downloading llama_index_program_openai-0.3.1-py3-none-any.whl (5.3 kB)\n",
      "Downloading llama_index_question_gen_openai-0.3.0-py3-none-any.whl (2.9 kB)\n",
      "Downloading llama_index_readers_file-0.4.4-py3-none-any.whl (39 kB)\n",
      "Downloading llama_index_readers_llama_parse-0.4.0-py3-none-any.whl (2.5 kB)\n",
      "Downloading dirtyjson-1.0.8-py3-none-any.whl (25 kB)\n",
      "Downloading filetype-1.2.0-py2.py3-none-any.whl (19 kB)\n",
      "Downloading llama_cloud-0.1.12-py3-none-any.whl (252 kB)\n",
      "Downloading llama_parse-0.6.0-py3-none-any.whl (4.8 kB)\n",
      "Downloading openai-1.61.1-py3-none-any.whl (463 kB)\n",
      "Downloading striprtf-0.0.26-py3-none-any.whl (6.9 kB)\n",
      "Downloading tiktoken-0.8.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m47.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading distro-1.9.0-py3-none-any.whl (20 kB)\n",
      "Downloading jiter-0.8.2-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (345 kB)\n",
      "Downloading llama_cloud_services-0.6.0-py3-none-any.whl (22 kB)\n",
      "Installing collected packages: striprtf, filetype, dirtyjson, jiter, distro, tiktoken, openai, llama-index-core, llama-cloud, llama-index-readers-file, llama-index-llms-openai, llama-index-indices-managed-llama-cloud, llama-index-embeddings-openai, llama-cloud-services, llama-parse, llama-index-multi-modal-llms-openai, llama-index-cli, llama-index-agent-openai, llama-index-readers-llama-parse, llama-index-program-openai, llama-index-question-gen-openai, llama-index\n",
      "Successfully installed dirtyjson-1.0.8 distro-1.9.0 filetype-1.2.0 jiter-0.8.2 llama-cloud-0.1.12 llama-cloud-services-0.6.0 llama-index-0.12.16 llama-index-agent-openai-0.4.5 llama-index-cli-0.4.0 llama-index-core-0.12.16.post1 llama-index-embeddings-openai-0.3.1 llama-index-indices-managed-llama-cloud-0.6.4 llama-index-llms-openai-0.3.18 llama-index-multi-modal-llms-openai-0.4.3 llama-index-program-openai-0.3.1 llama-index-question-gen-openai-0.3.0 llama-index-readers-file-0.4.4 llama-index-readers-llama-parse-0.4.0 llama-parse-0.6.0 openai-1.61.1 striprtf-0.0.26 tiktoken-0.8.0\n"
     ]
    }
   ],
   "source": [
    "!pip install llama-index\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kronos/anaconda3/envs/rapids-24.12/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from getpass import getpass\n",
    "from huggingface_hub import login"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "HF_Token = getpass()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "login(token = HF_Token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core.agent import ReActAgent\n",
    "from llama_index.llms.openai import OpenAI\n",
    "from llama_index.core.tools import FunctionTool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def multiply(a: float, b: float) -> float:\n",
    "    \"\"\"Multiply two numbers and returns the product\"\"\"\n",
    "    return a * b\n",
    "\n",
    "\n",
    "multiply_tool = FunctionTool.from_defaults(fn=multiply)\n",
    "\n",
    "\n",
    "def add(a: float, b: float) -> float:\n",
    "    \"\"\"Add two numbers and returns the sum\"\"\"\n",
    "    return a + b\n",
    "\n",
    "\n",
    "add_tool = FunctionTool.from_defaults(fn=add)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sqlalchemy import create_engine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "dbEngine = create_engine('sqlite:////home/kronos/Desktop/raman.db')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "r = pd.read_sql('select name from sqlite_master',dbEngine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sqlalchemy import text\n",
    "\n",
    "def schema(x: str) -> str:\n",
    "    sql = f\"SELECT sql FROM sqlite_master WHERE name = '{x}';\"\n",
    "    with dbEngine.connect() as conn:\n",
    "        result = conn.execute(text(sql))\n",
    "        return result.fetchall()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "r['schema'] = r['name'].map(schema)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>WPA_all_time_connect</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   name\n",
       "0  WPA_all_time_connect"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r[r.loc[:,'name']=='WPA_all_time_connect']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('CREATE TABLE \"WPA_all_time_connect\" (\\n\\t\"_id\"\\tTEXT,\\n\\t\"collectionType\"\\tTEXT,\\n\\t\"eventName\"\\tTEXT,\\n\\t\"createdAt\"\\tTEXT,\\n\\t\"partnerRegion\"\\tTEXT,\\n\\t\"sessionId\"\\tTEXT,\\n\\t\"data_careerId\"\\tTEXT,\\n\\t\"data_jobId\"\\tTEXT,\\n\\t\"data_programId\"\\tTEXT,\\n\\t\"data_resourceId\"\\tTEXT,\\n\\t\"WPA_id\"\\tTEXT\\n)',)]\n",
      "[('CREATE TABLE \"WAP_site_resources\" (\\n\\t\"data_careerId\"\\tTEXT,\\n\\t\"featured\"\\tTEXT,\\n\\t\"providerName\"\\tTEXT,\\n\\t\"updatedAt\"\\tTEXT,\\n\\t\"resource_tag\"\\tTEXT\\n)',)]\n",
      "[('CREATE TABLE \"WPA_individual\" (\\n\\t\"rural_type\"\\tTEXT,\\n\\t\"lastLoggedInAt\"\\tTEXT,\\n\\t\"myPathCompleted\"\\tTEXT,\\n\\t\"preferredRegion\"\\tTEXT,\\n\\t\"preferr ... (487 characters truncated) ... tTEXT,\\n\\t\"completed_jobs_milestone\"\\tTEXT,\\n\\t\"completed_training_milestone\"\\tTEXT,\\n\\t\"gender_3\"\\tTEXT,\\n\\t\"birth_year\"\\tTEXT,\\n\\t\"WPA_id\"\\tTEXT\\n)',)]\n",
      "[('CREATE TABLE \"WPA_pulse_survey\" (\\n\\t\"version\"\\tTEXT,\\n\\t\"year_quarter\"\\tTEXT,\\n\\t\"children\"\\tTEXT,\\n\\t\"concern_finances\"\\tTEXT,\\n\\t\"concern_health\"\\ ... (2910 characters truncated) ... ning_program_title\"\\tTEXT,\\n\\t\"training_support_services\"\\tTEXT,\\n\\t\"worked_past_six_months\"\\tTEXT,\\n\\t\"years_experience\"\\tTEXT,\\n\\t\"WPA_id\"\\tTEXT\\n)',)]\n",
      "[('CREATE TABLE \"WPA_site_careers\" (\\n\\t\"data_careerId\"\\tTEXT,\\n\\t\"createdAt\"\\tTEXT,\\n\\t\"education\"\\tTEXT,\\n\\t\"jobZone\"\\tTEXT,\\n\\t\"onetCode\"\\tTEXT,\\n\\t\"onetTitle\"\\tTEXT,\\n\\t\"title\"\\tTEXT,\\n\\t\"titleSingular\"\\tTEXT,\\n\\t\"updatedAt\"\\tTEXT\\n)',)]\n",
      "[('CREATE TABLE \"WPA_site_jobs\" (\\n\\t\"data_jobId\"\\tTEXT,\\n\\t\"career_area_name\"\\tTEXT,\\n\\t\"region\"\\tTEXT,\\n\\t\"company_name\"\\tTEXT,\\n\\t\"createdAt\"\\tTEXT,\\ ... (397 characters truncated) ... name\"\\tTEXT,\\n\\t\"remote_type_name\"\\tTEXT,\\n\\t\"onet\"\\tTEXT,\\n\\t\"onet_name\"\\tTEXT,\\n\\t\"salary\"\\tINTEGER,\\n\\t\"title_name\"\\tTEXT,\\n\\t\"updatedAt\"\\tTEXT\\n)',)]\n",
      "[('CREATE TABLE \"WPA_site_other_events\" (\\n\\t\"collectionType\"\\tTEXT,\\n\\t\"eventName\"\\tTEXT,\\n\\t\"eventType\"\\tTEXT,\\n\\t\"partnerRegion\"\\tTEXT,\\n\\t\"WPA_id\"\\tTEXT\\n)',)]\n",
      "[('CREATE TABLE \"WPA_site_programs\" (\\n\\t\"data_careerId\"\\tTEXT,\\n\\t\"name\"\\tTEXT,\\n\\t\"institution\"\\tTEXT,\\n\\t\"hours\"\\tTEXT,\\n\\t\"createdAt\"\\tTEXT,\\n\\t\"upd ... (201 characters truncated) ... _latitude\"\\tTEXT,\\n\\t\"location_coordinates_longitude\"\\tTEXT,\\n\\t\"careerFields\"\\tTEXT,\\n\\t\"industries\"\\tTEXT,\\n\\t\"catalog\"\\tTEXT,\\n\\t\"format\"\\tTEXT\\n)',)]\n"
     ]
    }
   ],
   "source": [
    "for i in r.schema:\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'llm' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m agent \u001b[38;5;241m=\u001b[39m ReActAgent\u001b[38;5;241m.\u001b[39mfrom_tools([multiply_tool, add_tool], llm\u001b[38;5;241m=\u001b[39m\u001b[43mllm\u001b[49m, verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'llm' is not defined"
     ]
    }
   ],
   "source": [
    "agent = ReActAgent.from_tools([multiply_tool, add_tool], llm=llm, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rapids-24.12",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
