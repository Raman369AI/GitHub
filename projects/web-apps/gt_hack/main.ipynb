{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kronos/anaconda3/envs/rapids-24.12/lib/python3.12/site-packages/pydantic/_internal/_config.py:345: UserWarning: Valid config keys have changed in V2:\n",
      "* 'fields' has been removed\n",
      "  warnings.warn(message, UserWarning)\n"
     ]
    }
   ],
   "source": [
    "from smolagents import CodeAgent, LiteLLMModel, CodeAgent, HfApiModel,tool, ToolCallingAgent\n",
    "model = LiteLLMModel(\n",
    "    model_id= \"ollama_chat/deepseek-r1:8b\", # This model is a bit weak for agentic behaviours though\n",
    "    api_base=\"http://localhost:11434\", # replace with 127.0.0.1:11434 or remote open-ai compatible server if necessary\n",
    "    api_key=\"\", # replace with API key if necessary\n",
    "    num_ctx=8192 # ollama default is 2048 which will fail horribly. 8192 works for easy tasks, more is better. Check https://huggingface.co/spaces/NyxKrage/LLM-Model-VRAM-Calculator to calculate how much VRAM this will need for the selected model.\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kronos/anaconda3/envs/rapids-24.12/lib/python3.12/site-packages/pydantic/_internal/_config.py:345: UserWarning: Valid config keys have changed in V2:\n",
      "* 'fields' has been removed\n",
      "  warnings.warn(message, UserWarning)\n"
     ]
    }
   ],
   "source": [
    "from smolagents import CodeAgent, LiteLLMModel, CodeAgent, HfApiModel,tool, ToolCallingAgent\n",
    "model_1 = LiteLLMModel(\n",
    "    model_id= \"ollama_chat/qwen2.5-coder:latest\", # This model is a bit weak for agentic behaviours though\n",
    "    api_base=\"http://localhost:11434\", # replace with 127.0.0.1:11434 or remote open-ai compatible server if necessary\n",
    "    api_key=\"\", # replace with API key if necessary\n",
    "    num_ctx=80960 # ollama default is 2048 which will fail horribly. 8192 works for easy tasks, more is better. Check https://huggingface.co/spaces/NyxKrage/LLM-Model-VRAM-Calculator to calculate how much VRAM this will need for the selected model.\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "@tool\n",
    "def mathematical_agent_tool() -> str:\n",
    "    '''This is a tool to access a csv named x and give it as an input to the tool which forecasts 6 month forecasts, \n",
    "    check for words ending with .csv in the input prompt and give it as the argument x to this tool, it returns a string variable called sentence and you need to stop here\n",
    "    Args: None\n",
    "\n",
    "    returns:\n",
    "    sentence: The formatted version of the 6 months forecasts \n",
    "        '''\n",
    "    import pandas as pd\n",
    "    import numpy as np\n",
    "    from pmdarima import auto_arima\n",
    "\n",
    "    from smolagents import ToolCallingAgent\n",
    "    from smolagents.default_tools import FinalAnswerTool\n",
    "    prices = pd.read_csv(\"iphone_price_trends_updated.csv\")\n",
    "    prices = prices.dropna(how='all')\n",
    "    prices['Date'] = pd.to_datetime(prices['Date'], format='%Y-%m')\n",
    "    df = prices[0:46]\n",
    "    df.set_index('Date', inplace=True)\n",
    "\n",
    "    y = df['New']\n",
    "    X = df[['CPIAUCSL', 'Unemployment_Rate', 'Interest Rates','CPI']]\n",
    "\n",
    "    # Fit the AutoARIMAX model\n",
    "    model = auto_arima(\n",
    "        y,\n",
    "        exogenous=X,\n",
    "        start_p=1, max_p=1,          # Constrain AR (p) to 1\n",
    "        start_q=4, max_q=4,          # Constrain MA (q) to 4\n",
    "        d=1,   \n",
    "        seasonal=False,           # Set to True if seasonality is suspected\n",
    "        trace=True,               # Display progress of parameter search\n",
    "        suppress_warnings=True,\n",
    "        stepwise=True             # Perform stepwise parameter selection\n",
    "    )\n",
    "    model.fit_with_exog_\n",
    "    # Print the selected ARIMAX order\n",
    "    print(f\"Best ARIMAX order: {model.order}\")\n",
    "    print(f\"Best Seasonal Order: {model.seasonal_order}\")\n",
    "\n",
    "    # Forecast next 6 months (provide future values for exogenous variables)\n",
    "    future_dates = pd.date_range(start='2024-07-01', periods=6, freq='M')\n",
    "    future_exog = pd.DataFrame({\n",
    "        'CPIAUCSL': prices['CPIAUCSL'][46:].values,\n",
    "        'Unemployment_Rate': prices['Unemployment_Rate'][46:].values,\n",
    "        'Interest Rates': prices['Interest Rates'][46:].values,\n",
    "        'CPI': prices['CPI'][46:].values,\n",
    "    }, index=future_dates)\n",
    "    print(future_exog)\n",
    "\n",
    "    # Make predictions\n",
    "    forecast = model.predict(n_periods=6, exogenous=future_exog)\n",
    "\n",
    "    # Combine forecast with future dates\n",
    "    forecast_df = pd.DataFrame({'Date': future_dates, 'Forecasted New Price': forecast})\n",
    "    forecast_df.set_index('Date', inplace=True)\n",
    "\n",
    "    # Display forecasted prices\n",
    "    future_exog = pd.DataFrame({\n",
    "        'CPIAUCSL': prices['CPIAUCSL'][46:],\n",
    "        'Unemployment_Rate': prices['Unemployment_Rate'][46:],\n",
    "        'Interest Rates': prices['Interest Rates'][46:],\n",
    "        'CPI': prices['CPI'][46:],\n",
    "    }, index=future_dates)\n",
    "    forecast = model.predict(n_periods=6, exogenous=future_exog)\n",
    "    sentence = ', '.join([f\"{index.strftime('%Y-%m-%d')} the price is {value}\" for index, value in forecast.items()])\n",
    "    return sentence\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Caution: you set an authorization for all imports, meaning your agent can decide to import any package it deems \n",
       "necessary. This might raise issues if the package is not installed in your environment. <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Caution: you set an authorization for all imports, meaning your agent can decide to import any package it deems \n",
       "necessary. This might raise issues if the package is not installed in your environment. \u001b[1;36m0\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "mathematical_agent = CodeAgent(tools=[mathematical_agent_tool], model=model_1,  add_base_tools=False, max_steps = 5, verbosity_level = 5,additional_authorized_imports = [\"*\"], name = 'mathematical_agent', description = \"access ###'iphone_price_trends_updated.csv' in the current working directory and give the name of the csv as input to mathematical_agent_tool, dont modify the final sentence variable the out should be the sentence as it is\" )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #d4b702; text-decoration-color: #d4b702\">╭───────────────────────────────────────── </span><span style=\"color: #d4b702; text-decoration-color: #d4b702; font-weight: bold\">New run - mathematical_agent</span><span style=\"color: #d4b702; text-decoration-color: #d4b702\"> ──────────────────────────────────────────╮</span>\n",
       "<span style=\"color: #d4b702; text-decoration-color: #d4b702\">│</span>                                                                                                                 <span style=\"color: #d4b702; text-decoration-color: #d4b702\">│</span>\n",
       "<span style=\"color: #d4b702; text-decoration-color: #d4b702\">│</span> <span style=\"font-weight: bold\">Call the tool, return the execution logs as the sentence variable</span>                                               <span style=\"color: #d4b702; text-decoration-color: #d4b702\">│</span>\n",
       "<span style=\"color: #d4b702; text-decoration-color: #d4b702\">│</span>                                                                                                                 <span style=\"color: #d4b702; text-decoration-color: #d4b702\">│</span>\n",
       "<span style=\"color: #d4b702; text-decoration-color: #d4b702\">╰─ LiteLLMModel - ollama_chat/qwen2.5-coder:latest ───────────────────────────────────────────────────────────────╯</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[38;2;212;183;2m╭─\u001b[0m\u001b[38;2;212;183;2m────────────────────────────────────────\u001b[0m\u001b[38;2;212;183;2m \u001b[0m\u001b[1;38;2;212;183;2mNew run - mathematical_agent\u001b[0m\u001b[38;2;212;183;2m \u001b[0m\u001b[38;2;212;183;2m─────────────────────────────────────────\u001b[0m\u001b[38;2;212;183;2m─╮\u001b[0m\n",
       "\u001b[38;2;212;183;2m│\u001b[0m                                                                                                                 \u001b[38;2;212;183;2m│\u001b[0m\n",
       "\u001b[38;2;212;183;2m│\u001b[0m \u001b[1mCall the tool, return the execution logs as the sentence variable\u001b[0m                                               \u001b[38;2;212;183;2m│\u001b[0m\n",
       "\u001b[38;2;212;183;2m│\u001b[0m                                                                                                                 \u001b[38;2;212;183;2m│\u001b[0m\n",
       "\u001b[38;2;212;183;2m╰─\u001b[0m\u001b[38;2;212;183;2m LiteLLMModel - ollama_chat/qwen2.5-coder:latest \u001b[0m\u001b[38;2;212;183;2m──────────────────────────────────────────────────────────────\u001b[0m\u001b[38;2;212;183;2m─╯\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #d4b702; text-decoration-color: #d4b702\">━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ </span><span style=\"font-weight: bold\">Step </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span><span style=\"color: #d4b702; text-decoration-color: #d4b702\"> ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[38;2;212;183;2m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ \u001b[0m\u001b[1mStep \u001b[0m\u001b[1;36m1\u001b[0m\u001b[38;2;212;183;2m ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold; font-style: italic\">Output message of the LLM:</span> <span style=\"color: #d4b702; text-decoration-color: #d4b702\">────────────────────────────────────────────────────────────────────────────────────────</span>\n",
       "<span style=\"color: #e6edf3; text-decoration-color: #e6edf3; background-color: #0d1117\">Thought: I need to call the </span><span style=\"color: #a5d6ff; text-decoration-color: #a5d6ff; background-color: #0d1117\">`mathematical_agent_tool`</span><span style=\"color: #e6edf3; text-decoration-color: #e6edf3; background-color: #0d1117\"> and return its output as the 'sentence' variable. This tool </span><span style=\"background-color: #0d1117\"> </span>\n",
       "<span style=\"color: #e6edf3; text-decoration-color: #e6edf3; background-color: #0d1117\">requires a CSV file as input, but since there is no specific file mentioned in this query, I will assume that the </span><span style=\"background-color: #0d1117\"> </span>\n",
       "<span style=\"color: #e6edf3; text-decoration-color: #e6edf3; background-color: #0d1117\">function will work without any arguments.</span><span style=\"background-color: #0d1117\">                                                                          </span>\n",
       "<span style=\"color: #e6edf3; text-decoration-color: #e6edf3; background-color: #0d1117\">Code:</span><span style=\"background-color: #0d1117\">                                                                                                              </span>\n",
       "<span style=\"color: #a5d6ff; text-decoration-color: #a5d6ff; background-color: #0d1117\">```py</span><span style=\"background-color: #0d1117\">                                                                                                              </span>\n",
       "<span style=\"color: #e6edf3; text-decoration-color: #e6edf3; background-color: #0d1117\">sentence </span><span style=\"color: #ff7b72; text-decoration-color: #ff7b72; background-color: #0d1117; font-weight: bold\">=</span><span style=\"color: #e6edf3; text-decoration-color: #e6edf3; background-color: #0d1117\"> mathematical_agent_tool()</span><span style=\"background-color: #0d1117\">                                                                               </span>\n",
       "<span style=\"color: #e6edf3; text-decoration-color: #e6edf3; background-color: #0d1117\">final_answer({</span><span style=\"color: #a5d6ff; text-decoration-color: #a5d6ff; background-color: #0d1117\">'answer'</span><span style=\"color: #e6edf3; text-decoration-color: #e6edf3; background-color: #0d1117\">: sentence})</span><span style=\"background-color: #0d1117\">                                                                                 </span>\n",
       "<span style=\"color: #a5d6ff; text-decoration-color: #a5d6ff; background-color: #0d1117\">```</span><span style=\"background-color: #0d1117\">                                                                                                                </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;3mOutput message of the LLM:\u001b[0m \u001b[38;2;212;183;2m────────────────────────────────────────────────────────────────────────────────────────\u001b[0m\n",
       "\u001b[38;2;230;237;243;48;2;13;17;23mThought:\u001b[0m\u001b[38;2;230;237;243;48;2;13;17;23m \u001b[0m\u001b[38;2;230;237;243;48;2;13;17;23mI\u001b[0m\u001b[38;2;230;237;243;48;2;13;17;23m \u001b[0m\u001b[38;2;230;237;243;48;2;13;17;23mneed\u001b[0m\u001b[38;2;230;237;243;48;2;13;17;23m \u001b[0m\u001b[38;2;230;237;243;48;2;13;17;23mto\u001b[0m\u001b[38;2;230;237;243;48;2;13;17;23m \u001b[0m\u001b[38;2;230;237;243;48;2;13;17;23mcall\u001b[0m\u001b[38;2;230;237;243;48;2;13;17;23m \u001b[0m\u001b[38;2;230;237;243;48;2;13;17;23mthe\u001b[0m\u001b[38;2;230;237;243;48;2;13;17;23m \u001b[0m\u001b[38;2;165;214;255;48;2;13;17;23m`mathematical_agent_tool`\u001b[0m\u001b[38;2;230;237;243;48;2;13;17;23m \u001b[0m\u001b[38;2;230;237;243;48;2;13;17;23mand\u001b[0m\u001b[38;2;230;237;243;48;2;13;17;23m \u001b[0m\u001b[38;2;230;237;243;48;2;13;17;23mreturn\u001b[0m\u001b[38;2;230;237;243;48;2;13;17;23m \u001b[0m\u001b[38;2;230;237;243;48;2;13;17;23mits\u001b[0m\u001b[38;2;230;237;243;48;2;13;17;23m \u001b[0m\u001b[38;2;230;237;243;48;2;13;17;23moutput\u001b[0m\u001b[38;2;230;237;243;48;2;13;17;23m \u001b[0m\u001b[38;2;230;237;243;48;2;13;17;23mas\u001b[0m\u001b[38;2;230;237;243;48;2;13;17;23m \u001b[0m\u001b[38;2;230;237;243;48;2;13;17;23mthe\u001b[0m\u001b[38;2;230;237;243;48;2;13;17;23m \u001b[0m\u001b[38;2;230;237;243;48;2;13;17;23m'sentence'\u001b[0m\u001b[38;2;230;237;243;48;2;13;17;23m \u001b[0m\u001b[38;2;230;237;243;48;2;13;17;23mvariable.\u001b[0m\u001b[38;2;230;237;243;48;2;13;17;23m \u001b[0m\u001b[38;2;230;237;243;48;2;13;17;23mThis\u001b[0m\u001b[38;2;230;237;243;48;2;13;17;23m \u001b[0m\u001b[38;2;230;237;243;48;2;13;17;23mtool\u001b[0m\u001b[38;2;230;237;243;48;2;13;17;23m \u001b[0m\u001b[48;2;13;17;23m \u001b[0m\n",
       "\u001b[38;2;230;237;243;48;2;13;17;23mrequires\u001b[0m\u001b[38;2;230;237;243;48;2;13;17;23m \u001b[0m\u001b[38;2;230;237;243;48;2;13;17;23ma\u001b[0m\u001b[38;2;230;237;243;48;2;13;17;23m \u001b[0m\u001b[38;2;230;237;243;48;2;13;17;23mCSV\u001b[0m\u001b[38;2;230;237;243;48;2;13;17;23m \u001b[0m\u001b[38;2;230;237;243;48;2;13;17;23mfile\u001b[0m\u001b[38;2;230;237;243;48;2;13;17;23m \u001b[0m\u001b[38;2;230;237;243;48;2;13;17;23mas\u001b[0m\u001b[38;2;230;237;243;48;2;13;17;23m \u001b[0m\u001b[38;2;230;237;243;48;2;13;17;23minput,\u001b[0m\u001b[38;2;230;237;243;48;2;13;17;23m \u001b[0m\u001b[38;2;230;237;243;48;2;13;17;23mbut\u001b[0m\u001b[38;2;230;237;243;48;2;13;17;23m \u001b[0m\u001b[38;2;230;237;243;48;2;13;17;23msince\u001b[0m\u001b[38;2;230;237;243;48;2;13;17;23m \u001b[0m\u001b[38;2;230;237;243;48;2;13;17;23mthere\u001b[0m\u001b[38;2;230;237;243;48;2;13;17;23m \u001b[0m\u001b[38;2;230;237;243;48;2;13;17;23mis\u001b[0m\u001b[38;2;230;237;243;48;2;13;17;23m \u001b[0m\u001b[38;2;230;237;243;48;2;13;17;23mno\u001b[0m\u001b[38;2;230;237;243;48;2;13;17;23m \u001b[0m\u001b[38;2;230;237;243;48;2;13;17;23mspecific\u001b[0m\u001b[38;2;230;237;243;48;2;13;17;23m \u001b[0m\u001b[38;2;230;237;243;48;2;13;17;23mfile\u001b[0m\u001b[38;2;230;237;243;48;2;13;17;23m \u001b[0m\u001b[38;2;230;237;243;48;2;13;17;23mmentioned\u001b[0m\u001b[38;2;230;237;243;48;2;13;17;23m \u001b[0m\u001b[38;2;230;237;243;48;2;13;17;23min\u001b[0m\u001b[38;2;230;237;243;48;2;13;17;23m \u001b[0m\u001b[38;2;230;237;243;48;2;13;17;23mthis\u001b[0m\u001b[38;2;230;237;243;48;2;13;17;23m \u001b[0m\u001b[38;2;230;237;243;48;2;13;17;23mquery,\u001b[0m\u001b[38;2;230;237;243;48;2;13;17;23m \u001b[0m\u001b[38;2;230;237;243;48;2;13;17;23mI\u001b[0m\u001b[38;2;230;237;243;48;2;13;17;23m \u001b[0m\u001b[38;2;230;237;243;48;2;13;17;23mwill\u001b[0m\u001b[38;2;230;237;243;48;2;13;17;23m \u001b[0m\u001b[38;2;230;237;243;48;2;13;17;23massume\u001b[0m\u001b[38;2;230;237;243;48;2;13;17;23m \u001b[0m\u001b[38;2;230;237;243;48;2;13;17;23mthat\u001b[0m\u001b[38;2;230;237;243;48;2;13;17;23m \u001b[0m\u001b[38;2;230;237;243;48;2;13;17;23mthe\u001b[0m\u001b[38;2;230;237;243;48;2;13;17;23m \u001b[0m\u001b[48;2;13;17;23m \u001b[0m\n",
       "\u001b[38;2;230;237;243;48;2;13;17;23mfunction\u001b[0m\u001b[38;2;230;237;243;48;2;13;17;23m \u001b[0m\u001b[38;2;230;237;243;48;2;13;17;23mwill\u001b[0m\u001b[38;2;230;237;243;48;2;13;17;23m \u001b[0m\u001b[38;2;230;237;243;48;2;13;17;23mwork\u001b[0m\u001b[38;2;230;237;243;48;2;13;17;23m \u001b[0m\u001b[38;2;230;237;243;48;2;13;17;23mwithout\u001b[0m\u001b[38;2;230;237;243;48;2;13;17;23m \u001b[0m\u001b[38;2;230;237;243;48;2;13;17;23many\u001b[0m\u001b[38;2;230;237;243;48;2;13;17;23m \u001b[0m\u001b[38;2;230;237;243;48;2;13;17;23marguments.\u001b[0m\u001b[48;2;13;17;23m                                                                          \u001b[0m\n",
       "\u001b[38;2;230;237;243;48;2;13;17;23mCode:\u001b[0m\u001b[48;2;13;17;23m                                                                                                              \u001b[0m\n",
       "\u001b[38;2;165;214;255;48;2;13;17;23m```\u001b[0m\u001b[38;2;165;214;255;48;2;13;17;23mpy\u001b[0m\u001b[48;2;13;17;23m                                                                                                              \u001b[0m\n",
       "\u001b[38;2;230;237;243;48;2;13;17;23msentence\u001b[0m\u001b[38;2;230;237;243;48;2;13;17;23m \u001b[0m\u001b[1;38;2;255;123;114;48;2;13;17;23m=\u001b[0m\u001b[38;2;230;237;243;48;2;13;17;23m \u001b[0m\u001b[38;2;230;237;243;48;2;13;17;23mmathematical_agent_tool\u001b[0m\u001b[38;2;230;237;243;48;2;13;17;23m(\u001b[0m\u001b[38;2;230;237;243;48;2;13;17;23m)\u001b[0m\u001b[48;2;13;17;23m                                                                               \u001b[0m\n",
       "\u001b[38;2;230;237;243;48;2;13;17;23mfinal_answer\u001b[0m\u001b[38;2;230;237;243;48;2;13;17;23m(\u001b[0m\u001b[38;2;230;237;243;48;2;13;17;23m{\u001b[0m\u001b[38;2;165;214;255;48;2;13;17;23m'\u001b[0m\u001b[38;2;165;214;255;48;2;13;17;23manswer\u001b[0m\u001b[38;2;165;214;255;48;2;13;17;23m'\u001b[0m\u001b[38;2;230;237;243;48;2;13;17;23m:\u001b[0m\u001b[38;2;230;237;243;48;2;13;17;23m \u001b[0m\u001b[38;2;230;237;243;48;2;13;17;23msentence\u001b[0m\u001b[38;2;230;237;243;48;2;13;17;23m}\u001b[0m\u001b[38;2;230;237;243;48;2;13;17;23m)\u001b[0m\u001b[48;2;13;17;23m                                                                                 \u001b[0m\n",
       "\u001b[38;2;165;214;255;48;2;13;17;23m```\u001b[0m\u001b[48;2;13;17;23m                                                                                                                \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"> ─ <span style=\"font-weight: bold\">Executing parsed code:</span> ──────────────────────────────────────────────────────────────────────────────────────── \n",
       "  <span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">sentence </span><span style=\"color: #ff4689; text-decoration-color: #ff4689; background-color: #272822\">=</span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\"> mathematical_agent_tool()</span><span style=\"background-color: #272822\">                                                                           </span>  \n",
       "  <span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">final_answer({</span><span style=\"color: #e6db74; text-decoration-color: #e6db74; background-color: #272822\">'answer'</span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">: sentence})</span><span style=\"background-color: #272822\">                                                                             </span>  \n",
       " ───────────────────────────────────────────────────────────────────────────────────────────────────────────────── \n",
       "</pre>\n"
      ],
      "text/plain": [
       " ─ \u001b[1mExecuting parsed code:\u001b[0m ──────────────────────────────────────────────────────────────────────────────────────── \n",
       "  \u001b[38;2;248;248;242;48;2;39;40;34msentence\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m \u001b[0m\u001b[38;2;255;70;137;48;2;39;40;34m=\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34mmathematical_agent_tool\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m(\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m)\u001b[0m\u001b[48;2;39;40;34m                                                                           \u001b[0m  \n",
       "  \u001b[38;2;248;248;242;48;2;39;40;34mfinal_answer\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m(\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m{\u001b[0m\u001b[38;2;230;219;116;48;2;39;40;34m'\u001b[0m\u001b[38;2;230;219;116;48;2;39;40;34manswer\u001b[0m\u001b[38;2;230;219;116;48;2;39;40;34m'\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m:\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34msentence\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m}\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m)\u001b[0m\u001b[48;2;39;40;34m                                                                             \u001b[0m  \n",
       " ───────────────────────────────────────────────────────────────────────────────────────────────────────────────── \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performing stepwise search to minimize aic\n",
      " ARIMA(1,1,4)(0,0,0)[0] intercept   : AIC=inf, Time=0.08 sec\n",
      " ARIMA(0,1,0)(0,0,0)[0] intercept   : AIC=503.368, Time=0.01 sec\n",
      " ARIMA(1,1,0)(0,0,0)[0] intercept   : AIC=505.209, Time=0.02 sec\n",
      " ARIMA(0,1,1)(0,0,0)[0] intercept   : AIC=504.982, Time=0.02 sec\n",
      " ARIMA(0,1,0)(0,0,0)[0]             : AIC=506.087, Time=0.01 sec\n",
      " ARIMA(1,1,1)(0,0,0)[0] intercept   : AIC=506.464, Time=0.03 sec\n",
      "\n",
      "Best model:  ARIMA(0,1,0)(0,0,0)[0] intercept\n",
      "Total fit time: 0.164 seconds\n",
      "Best ARIMAX order: (0, 1, 0)\n",
      "Best Seasonal Order: (0, 0, 0, 0)\n",
      "            CPIAUCSL  Unemployment_Rate  Interest Rates       CPI\n",
      "2024-07-31   314.131                4.2        1.664190  3.701742\n",
      "2024-08-31   314.851                4.1        1.581581  4.146461\n",
      "2024-09-30   315.564                4.1        1.480148  3.698695\n",
      "2024-10-31   316.449                4.2        1.958417  3.226070\n",
      "2024-11-30   317.603                4.1        1.824369  3.234511\n",
      "2024-12-31   319.086                4.0        2.055532  3.930193\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kronos/anaconda3/envs/rapids-24.12/lib/python3.12/site-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "/home/kronos/anaconda3/envs/rapids-24.12/lib/python3.12/site-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "/home/kronos/anaconda3/envs/rapids-24.12/lib/python3.12/site-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "/home/kronos/anaconda3/envs/rapids-24.12/lib/python3.12/site-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "/home/kronos/anaconda3/envs/rapids-24.12/lib/python3.12/site-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "/home/kronos/anaconda3/envs/rapids-24.12/lib/python3.12/site-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "/home/kronos/anaconda3/envs/rapids-24.12/lib/python3.12/site-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "/tmp/ipykernel_61476/1453235054.py:43: FutureWarning: 'M' is deprecated and will be removed in a future version, please use 'ME' instead.\n",
      "  future_dates = pd.date_range(start='2024-07-01', periods=6, freq='M')\n",
      "/home/kronos/anaconda3/envs/rapids-24.12/lib/python3.12/site-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "/home/kronos/anaconda3/envs/rapids-24.12/lib/python3.12/site-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #d4b702; text-decoration-color: #d4b702; font-weight: bold\">Out - Final answer: {'answer': '2024-08-01 the price is 299.3333333333333, 2024-09-01 the price is </span>\n",
       "<span style=\"color: #d4b702; text-decoration-color: #d4b702; font-weight: bold\">278.66666666666663, 2024-10-01 the price is 257.99999999999994, 2024-11-01 the price is 237.33333333333326, </span>\n",
       "<span style=\"color: #d4b702; text-decoration-color: #d4b702; font-weight: bold\">2024-12-01 the price is 216.66666666666657, 2025-01-01 the price is 195.9999999999999'}</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;38;2;212;183;2mOut - Final answer: {'answer': '2024-08-01 the price is 299.3333333333333, 2024-09-01 the price is \u001b[0m\n",
       "\u001b[1;38;2;212;183;2m278.66666666666663, 2024-10-01 the price is 257.99999999999994, 2024-11-01 the price is 237.33333333333326, \u001b[0m\n",
       "\u001b[1;38;2;212;183;2m2024-12-01 the price is 216.66666666666657, 2025-01-01 the price is 195.9999999999999'}\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">[Step 0: Duration 8.79 seconds| Input tokens: 2,076 | Output tokens: 81]</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2m[Step 0: Duration 8.79 seconds| Input tokens: 2,076 | Output tokens: 81]\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sentence = mathematical_agent.run(f\"Call the tool, return the execution logs as the sentence variable\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performing stepwise search to minimize aic\n",
      " ARIMA(1,1,4)(0,0,0)[0] intercept   : AIC=inf, Time=0.07 sec\n",
      " ARIMA(0,1,0)(0,0,0)[0] intercept   : AIC=503.368, Time=0.01 sec\n",
      " ARIMA(1,1,0)(0,0,0)[0] intercept   : AIC=505.209, Time=0.02 sec\n",
      " ARIMA(0,1,1)(0,0,0)[0] intercept   : AIC=504.982, Time=0.02 sec\n",
      " ARIMA(0,1,0)(0,0,0)[0]             : AIC=506.087, Time=0.01 sec\n",
      " ARIMA(1,1,1)(0,0,0)[0] intercept   : AIC=506.464, Time=0.03 sec\n",
      "\n",
      "Best model:  ARIMA(0,1,0)(0,0,0)[0] intercept\n",
      "Total fit time: 0.150 seconds\n",
      "Best ARIMAX order: (0, 1, 0)\n",
      "Best Seasonal Order: (0, 0, 0, 0)\n",
      "            CPIAUCSL  Unemployment_Rate  Interest Rates       CPI\n",
      "2024-07-31   314.131                4.2        1.664190  3.701742\n",
      "2024-08-31   314.851                4.1        1.581581  4.146461\n",
      "2024-09-30   315.564                4.1        1.480148  3.698695\n",
      "2024-10-31   316.449                4.2        1.958417  3.226070\n",
      "2024-11-30   317.603                4.1        1.824369  3.234511\n",
      "2024-12-31   319.086                4.0        2.055532  3.930193\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kronos/anaconda3/envs/rapids-24.12/lib/python3.12/site-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "/home/kronos/anaconda3/envs/rapids-24.12/lib/python3.12/site-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "/home/kronos/anaconda3/envs/rapids-24.12/lib/python3.12/site-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "/home/kronos/anaconda3/envs/rapids-24.12/lib/python3.12/site-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "/home/kronos/anaconda3/envs/rapids-24.12/lib/python3.12/site-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "/home/kronos/anaconda3/envs/rapids-24.12/lib/python3.12/site-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "/home/kronos/anaconda3/envs/rapids-24.12/lib/python3.12/site-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "/tmp/ipykernel_63616/1453235054.py:43: FutureWarning: 'M' is deprecated and will be removed in a future version, please use 'ME' instead.\n",
      "  future_dates = pd.date_range(start='2024-07-01', periods=6, freq='M')\n",
      "/home/kronos/anaconda3/envs/rapids-24.12/lib/python3.12/site-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "/home/kronos/anaconda3/envs/rapids-24.12/lib/python3.12/site-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# After executing a tool and getting its result\n",
    "tool_result = mathematical_agent.execute_tool_call('mathematical_agent_tool',{})\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "mathematical_agent.state = tool_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2024-08-01 the price is 299.3333333333333, 2024-09-01 the price is 278.66666666666663, 2024-10-01 the price is 257.99999999999994, 2024-11-01 the price is 237.33333333333326, 2024-12-01 the price is 216.66666666666657, 2025-01-01 the price is 195.9999999999999'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mathematical_agent.state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<bound method AgentMemory.replay of <smolagents.memory.AgentMemory object at 0x7a314b38dd00>>\n"
     ]
    }
   ],
   "source": [
    "print(mathematical_agent.memory.replay)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Create the model\n",
    "\n",
    "@tool\n",
    "def market_preds(sentence: str) -> str:\n",
    "    \"\"\"\n",
    "    Returns the interpretation of the forecasts from the purview of the real word events\n",
    "\n",
    "    Args:\n",
    "        sentence: the forecasts for 6 months\n",
    "    \"\"\"\n",
    "    description = \"\"\"\n",
    "    This is about a product called Apple Iphone 12 128 GB, you will take the the forecast of the price in dollars and give the macroeconomic or product related or Geopolitical or other events that influenced the increase or decrease, refer internet for the events\"\"\"\n",
    "    import os\n",
    "    import google.generativeai as genai\n",
    "\n",
    "    genai.configure(api_key=\"*\")\n",
    "    generation_config = {\n",
    "        \"temperature\": 0.7,\n",
    "        \"top_p\": 0.95,\n",
    "        \"top_k\": 64,\n",
    "        \"max_output_tokens\": 4096,\n",
    "        \"response_mime_type\": \"text/plain\",\n",
    "    }\n",
    "\n",
    "    model = genai.GenerativeModel(\n",
    "        model_name=\"gemini-2.0-pro-exp-02-05\",\n",
    "        generation_config=generation_config,\n",
    "    )\n",
    "\n",
    "    chat_session = model.start_chat(\n",
    "        history=[]\n",
    "    )\n",
    "    events = chat_session.send_message(f\"Give me all events from February 2020 to February 2025 in month and year format that affect apple's supply chain or events that can affect the price of a iphone, including supply chain , quality issues, competitor launch, or new product launch, geopolitics, tariffs, China, taiwan, antitrust and quality issues\")\n",
    "    response = chat_session.send_message(f\"{sentence} is the forecast of iphone 12 128GB for 6 months and {events.text} is the events that can affect the price of an iphone, evaluate the forecast and events and associate each forecast with the corresponding event and give an elaborate association of events and price forecast \")\n",
    "    return response.text\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "market_agent = CodeAgent(tools=[market_preds], model=model_1,  add_base_tools=False, max_steps = 5, verbosity_level = 5, name = \"market_agent\", additional_authorized_imports=[\"*\"],description = 'This agent helps in doing market research for the product described and returns the interpreted message')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "market = market_agent.run(f\"{sentence} is the input to the market_preds and the forecast of iphone 12 128GB for 6 months and the events that can affect the price of an iphone, evaluate the forecast and events and associate each forecast with the corresponding event and give an elaborate association of events and price forecast , t, return the ###'execution logs' as Final Answer\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from smolagents import ToolCallingAgent,CodeAgent\n",
    "from smolagents.default_tools import FinalAnswerTool,DuckDuckGoSearchTool, VisitWebpageTool\n",
    "\n",
    "web_agent = CodeAgent(tools=[DuckDuckGoSearchTool(),VisitWebpageTool()], model=model_1,  add_base_tools=True, max_steps = 5, verbosity_level = 5 , additional_authorized_imports=[\"*\"], name = \"web_agent\", description = \"Write code to go to duckduckgo and for iphone shipments and redo the same iphone revenue share, sumamrize the search results be specific with numbers and years , try to get years 2020 to 2025 and print the summary\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "web_search = web_agent.run(f\"\"\"Write code to go to duckduckgo and search for quanitty of iphone shipments and redo the same iphone revenue share, sumamrize the search results be specific with numbers and years , try to get years 2020 to 2025 and print as a complete sentence by sumamrizing the search results of each year with any additional information with the quantities and revenue for each year\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tool\n",
    "def recommend_tool(sentence: str, web_search: str, market:list) -> str:\n",
    "    \"\"\"\n",
    "    Returns the pricing optimization advice\n",
    "\n",
    "    Args:\n",
    "        sentence: the forecasts for 6 months\n",
    "        web_search: The quantities and revenue associated with the iphone sales\n",
    "        market: The events that affect the iphone price and their mapping with the forecast\n",
    "    \"\"\"\n",
    "    description = \"\"\"\n",
    "    This is about a product called Apple Iphone 12 128 GB, you will take the the forecast of the price in dollars and give the macroeconomic or product related or Geopolitical or other events that influenced the increase or decrease, refer internet for the events\"\"\"\n",
    "    import os\n",
    "    import google.generativeai as genai\n",
    "\n",
    "    genai.configure(api_key=\"*\")\n",
    "    generation_config = {\n",
    "        \"temperature\": 0.1,\n",
    "        \"top_p\": 0.95,\n",
    "        \"top_k\": 64,\n",
    "        \"max_output_tokens\": 4096,\n",
    "        \"response_mime_type\": \"text/plain\",\n",
    "    }\n",
    "\n",
    "    model = genai.GenerativeModel(\n",
    "        model_name=\"gemini-2.0-pro-exp-02-05\",\n",
    "        generation_config=generation_config,\n",
    "    )\n",
    "\n",
    "    chat_session = model.start_chat(\n",
    "        history=[]\n",
    "    )\n",
    "    total = sentence + web_search +' '.join(market)\n",
    "    response = chat_session.send_message(f\"{total} is the output of all the three agents, the forecasts for the next 6 months , the events that might have impacted the iphone price and historical revenue and quantity numbers, now based on all these try price elasticity and other price optimisation and dynamic pricing theories and give a condensed recommendation of the pricing strategy along with the future expectations of the price \")\n",
    "    return response.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "recommend_agent = CodeAgent(tools=[recommend_tool], model=model_1,  add_base_tools=False, max_steps = 5, verbosity_level = 5, name = \"recommend_agent\", additional_authorized_imports=[\"*\"],description = 'This agent helps in consolidating the outputs of the other three and gives the pricing strategy recommendations')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "recommend_agent.run(\"{Given are the output of all the three agents, the forecasts for the next 6 months , the events that might have impacted the iphone price and historical revenue and quantity numbers, now based on all these try price elasticity and other price optimisation and dynamic pricing theories and give a condensed recommendation of the pricing strategy along with the future expectations of the average price for  all iphone models in common and also the risks associated, geopolitical, social, economic, macro economic, monetary summarize in one paragraph\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import gradio as gr\n",
    "\n",
    "# Define the function that runs the agents and generates the recommendation\n",
    "def process_prompt(prompt):\n",
    "    # Run the mathematical agent\n",
    "    sentence = mathematical_agent.run(prompt)\n",
    "    \n",
    "    # Run the market agent\n",
    "    market = market_agent.run(f\"{sentence} is the input to the market_preds...\")\n",
    "    \n",
    "    # Run the web search agent\n",
    "    web_search = web_agent.run(market)\n",
    "    \n",
    "    # Run the recommendation agent\n",
    "    recommendation = recommend_agent.run(\"Given are the output of all the three agents, the forecasts for the next 6 months , the events that might have impacted the iphone price and historical revenue and quantity numbers, now based on all these try price elasticity and other price optimisation and dynamic pricing theories and give a condensed recommendation of the pricing strategy along with the future expectations of the average price for  all iphone models in common and also the risks associated, geopolitical, social, economic, macro economic, monetary summarize in one paragraph\")\n",
    "    \n",
    "    # Return the outputs from the agents\n",
    "    return sentence, market, web_search, recommendation\n",
    "\n",
    "# Create the Gradio interface\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with gr.Blocks() as demo:\n",
    "    # Define the input component\n",
    "    prompt = gr.Textbox(label=\"Prompt\", lines=5)  # Allow for larger text input\n",
    "    \n",
    "    # Define the output components\n",
    "    sentence_output = gr.Textbox(label=\"Mathematical Agent Output\", lines=5)  # Allow for larger text output\n",
    "    market_output = gr.Textbox(label=\"Market Agent Output\", lines=5)  # Allow for larger text output\n",
    "    web_search_output = gr.Textbox(label=\"Web Search Agent Output\", lines=5)  # Allow for larger text output\n",
    "    recommendation_output = gr.Textbox(label=\"Recommendation\", lines=5)  # Allow for larger text output\n",
    "    \n",
    "    # Define the button to trigger the function\n",
    "    submit_btn = gr.Button(\"Submit\")\n",
    "    \n",
    "    # Define the event listener for the button click\n",
    "    submit_btn.click(\n",
    "        fn=process_prompt,\n",
    "        inputs=prompt,\n",
    "        outputs=[sentence_output, market_output, web_search_output, recommendation_output]\n",
    "    )\n",
    "\n",
    "# Launch the Gradio app\n",
    "if __name__ == \"__main__\":\n",
    "    demo.launch(show_error=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rapids-24.12",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
