{"cells":[{"cell_type":"markdown","id":"c7403a5e-b023-465a-a38b-5dbf4b2e03a5","metadata":{},"outputs":[],"source":["<p style=\"text-align:center\">\n","    <a href=\"https://skills.network\" target=\"_blank\">\n","    <img src=\"https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/assets/logos/SN_web_lightmode.png\" width=\"200\" alt=\"Skills Network Logo\">\n","    </a>\n","</p>\n"]},{"cell_type":"markdown","id":"a9d038b3-78e8-4f1e-be50-be48022d65e7","metadata":{},"outputs":[],"source":["<h1>Activation Functions</h1> \n"]},{"cell_type":"markdown","id":"1ece3a72-f94c-417f-ad16-89096a79b7a2","metadata":{},"outputs":[],"source":["<h2>Objective</h2><ul><li> How to apply different Activation functions in Neural Network.</li></ul> \n"]},{"cell_type":"markdown","id":"4da1ce62-39ea-480c-b162-5eac9f8a1873","metadata":{},"outputs":[],"source":["<h2>Table of Contents</h2>\n","<p>In this lab, you will cover logistic regression by using PyTorch.</p>\n","\n","<ul>\n","    <li><a href=\"#Log\">Logistic Function</a></li>\n","    <li><a href=\"#Tanh\">Tanh</a></li>\n","    <li><a href=\"#Relu\">Relu</a></li>\n","    <li><a href=\"#Compare\">Compare Activation Functions</a></li>\n","</ul>\n","<p>Estimated Time Needed: <strong>15 min</strong></p>\n","\n","<hr>\n"]},{"cell_type":"markdown","id":"dceeeeca-fafa-4855-8fdc-32b348e45698","metadata":{},"outputs":[],"source":["We'll need the following libraries\n"]},{"cell_type":"code","id":"9fb1028b-cf38-4501-83d8-f1c0e1deafa7","metadata":{},"outputs":[],"source":["# Import the libraries we need for this lab\n\nimport torch.nn as nn\nimport torch\n\nimport matplotlib.pyplot as plt\ntorch.manual_seed(2)"]},{"cell_type":"markdown","id":"3456883b-0381-49a1-b36c-9f25bc2892d1","metadata":{},"outputs":[],"source":["<!--Empty Space for separating topics-->\n"]},{"cell_type":"markdown","id":"091daa8f-d728-46aa-8805-8ec9df31cc1f","metadata":{},"outputs":[],"source":["<h2 id=\"Log\">Logistic Function</h2>\n"]},{"cell_type":"markdown","id":"4fd579fc-c794-47cf-836b-3d84e46b745e","metadata":{},"outputs":[],"source":["Create a tensor ranging from -10 to 10: \n"]},{"cell_type":"code","id":"9dad216a-016f-4163-b2f0-5f69d8d2b28c","metadata":{},"outputs":[],"source":["# Create a tensor\n\nz = torch.arange(-10, 10, 0.1,).view(-1, 1)"]},{"cell_type":"markdown","id":"738f26c8-e45c-4c06-a9e1-dc4599a7d1b6","metadata":{},"outputs":[],"source":["When you use sequential, you can create a sigmoid object: \n"]},{"cell_type":"code","id":"dfc0c7e7-32d3-4e18-9780-d42402154fb2","metadata":{},"outputs":[],"source":["# Create a sigmoid object\n\nsig = nn.Sigmoid()"]},{"cell_type":"markdown","id":"194eaccd-bed8-43a7-b947-1dd8d86eba66","metadata":{},"outputs":[],"source":["Apply the element-wise function Sigmoid with the object:\n"]},{"cell_type":"code","id":"9df9bead-8045-495c-b03b-19406af05beb","metadata":{},"outputs":[],"source":["# Make a prediction of sigmoid function\n\nyhat = sig(z)"]},{"cell_type":"markdown","id":"eb9f7f0c-5748-4516-8b3d-75942ee99f00","metadata":{},"outputs":[],"source":["Plot the results: \n"]},{"cell_type":"code","id":"20335b35-b2eb-49c4-8040-97f2ffa69a5b","metadata":{},"outputs":[],"source":["# Plot the result\n\nplt.plot(z.detach().numpy(),yhat.detach().numpy())\nplt.xlabel('z')\nplt.ylabel('yhat')"]},{"cell_type":"markdown","id":"3d76b9db-5de4-46b2-bfc5-12b2a6ef0228","metadata":{},"outputs":[],"source":["For custom modules, call the sigmoid from the torch (<code>nn.functional</code> for the old version), which applies the element-wise sigmoid from the function module and plots the results:\n"]},{"cell_type":"code","id":"42db0ff4-04e8-4ce6-a6d6-9651fb5eea99","metadata":{},"outputs":[],"source":["# Use the build in function to predict the result\n\nyhat = torch.sigmoid(z)\nplt.plot(z.numpy(), yhat.numpy())\n\nplt.show()"]},{"cell_type":"markdown","id":"a240e618-bf9c-4754-a520-ffec8db356b0","metadata":{},"outputs":[],"source":["<!--Empty Space for separating topics-->\n"]},{"cell_type":"markdown","id":"51778467-c499-442e-a19e-c5e0ba448c63","metadata":{},"outputs":[],"source":["<h2 id=\"Tanh\">Tanh</h2>\n"]},{"cell_type":"markdown","id":"c637ab6a-5af4-4c3e-8bc1-a4b92b8d6c63","metadata":{},"outputs":[],"source":["When you use sequential, you can create a tanh object:\n"]},{"cell_type":"code","id":"8ff3e2a8-dc85-460a-a8c1-b8015f09fdd8","metadata":{},"outputs":[],"source":["# Create a tanh object\n\nTANH = nn.Tanh()"]},{"cell_type":"markdown","id":"f408a2a4-00fa-4f83-8e8b-68e8cde3677a","metadata":{},"outputs":[],"source":["Call the object and plot it:\n"]},{"cell_type":"code","id":"52a84225-158f-43ed-86ea-3ddb840d8ac1","metadata":{},"outputs":[],"source":["# Make the prediction using tanh object\n\nyhat = TANH(z)\nplt.plot(z.numpy(), yhat.numpy())\nplt.show()"]},{"cell_type":"markdown","id":"b1ccca87-f946-412a-a54a-227f55a0fbe7","metadata":{},"outputs":[],"source":["\n","For custom modules, call the Tanh object from the torch (nn.functional for the old version), which applies the element-wise sigmoid from the function module and plots the results:\n"]},{"cell_type":"code","id":"3ae1832f-114b-4bea-a350-c7862c5bfaec","metadata":{},"outputs":[],"source":["# Make the prediction using the build-in tanh object\n\nyhat = torch.tanh(z)\nplt.plot(z.numpy(), yhat.numpy())\nplt.show()"]},{"cell_type":"markdown","id":"a4f2b926-3418-4bc5-a5a8-5d6abea91914","metadata":{},"outputs":[],"source":["<!--Empty Space for separating topics-->\n"]},{"cell_type":"markdown","id":"01931d1c-ae59-4365-8b04-3b6665fbd63c","metadata":{},"outputs":[],"source":["<h2 id=\"Relu\">Relu</h2>\n"]},{"cell_type":"markdown","id":"c08806d5-a3f5-4fdc-825c-ebddcff6f582","metadata":{},"outputs":[],"source":["When you use sequential, you can create a Relu object: \n"]},{"cell_type":"code","id":"bc46cb19-8ecc-48fa-80f4-ed78d3e7720b","metadata":{},"outputs":[],"source":["# Create a relu object and make the prediction\n\nRELU = nn.ReLU()\nyhat = RELU(z)\nplt.plot(z.numpy(), yhat.numpy())"]},{"cell_type":"markdown","id":"1383bb7e-19e8-40f1-83ac-4da0b1055dfc","metadata":{},"outputs":[],"source":["For custom modules, call the relu object from the nn.functional, which applies the element-wise sigmoid from the function module and plots the results:\n"]},{"cell_type":"code","id":"37d9e366-4bca-4983-a75a-8a0cfb2af256","metadata":{},"outputs":[],"source":["# Use the build-in function to make the prediction\n\nyhat = torch.relu(z)\nplt.plot(z.numpy(), yhat.numpy())\nplt.show()"]},{"cell_type":"markdown","id":"d37a5012-9532-462a-88df-28b51d95b4d5","metadata":{},"outputs":[],"source":["<a id=\"ref3\"></a>\n","<h2> Compare Activation Functions </h2>\n"]},{"cell_type":"code","id":"8dccba02-f0d5-48ab-847c-ec2c44562020","metadata":{},"outputs":[],"source":["# Plot the results to compare the activation functions\n\nx = torch.arange(-2, 2, 0.1).view(-1, 1)\nplt.plot(x.numpy(), torch.relu(x).numpy(), label='relu')\nplt.plot(x.numpy(), torch.sigmoid(x).numpy(), label='sigmoid')\nplt.plot(x.numpy(), torch.tanh(x).numpy(), label='tanh')\nplt.legend()"]},{"cell_type":"markdown","id":"68027bc4-21de-4e9f-8f78-180ef0270e9a","metadata":{},"outputs":[],"source":["<a id=\"ref4\"></a>\n","<h2> Practice </h2>\n"]},{"cell_type":"markdown","id":"3298a17f-ba30-48ce-a9c2-21d63e0b2a3d","metadata":{},"outputs":[],"source":["Compare the activation functions with a tensor in the range <i>(-1, 1)</i>\n"]},{"cell_type":"code","id":"eda82602-4ad3-4e02-9513-5894acffecd5","metadata":{},"outputs":[],"source":["# Practice: Compare the activation functions again using a tensor in the range (-1, 1)\n\n# Type your code here"]},{"cell_type":"markdown","id":"88581a9d-5ccb-45ab-a559-850933c52689","metadata":{},"outputs":[],"source":["Double-click <b>here</b> for the solution.\n","\n","<!-- \n","x = torch.arange(-1, 1, 0.1).view(-1, 1)\n","plt.plot(x.numpy(), torch.relu(x).numpy(), label = 'relu')\n","plt.plot(x.numpy(), torch.sigmoid(x).numpy(), label = 'sigmoid')\n","plt.plot(x.numpy(), torch.tanh(x).numpy(), label = 'tanh')\n","plt.legend()\n","-->\n"]},{"cell_type":"markdown","id":"7e828b15-03a5-44c2-b3c1-6b5993ffdb91","metadata":{},"outputs":[],"source":["\n","<a href=\"https://dataplatform.cloud.ibm.com/registration/stepone?utm_source=skills_network&utm_content=in_lab_content_link&utm_id=Lab-IBMDeveloperSkillsNetwork-DL0110EN-SkillsNetwork&context=cpdaas&apps=data_science_experience%2Cwatson_machine_learning\"><img src=\"https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBMDeveloperSkillsNetwork-DL0110EN-SkillsNetwork/Template/module%201/images/Watson_Studio.png\"></a>\n"]},{"cell_type":"markdown","id":"78f7824a-3ba8-4e30-a2b0-6d34ae8ac728","metadata":{},"outputs":[],"source":["<!--Empty Space for separating topics-->\n"]},{"cell_type":"markdown","id":"9890ea6e-1b3d-4029-ad1c-c39e36edf9b6","metadata":{},"outputs":[],"source":["<h2>About the Authors:</h2> \n","\n","<a href=\"https://www.linkedin.com/in/joseph-s-50398b136/\">Joseph Santarcangelo</a> has a PhD in Electrical Engineering, his research focused on using machine learning, signal processing, and computer vision to determine how videos impact human cognition. Joseph has been working for IBM since he completed his PhD. \n"]},{"cell_type":"markdown","id":"c9a7c15b-e979-460b-bc96-ea2390cac414","metadata":{},"outputs":[],"source":["Other contributors: <a href=\"https://www.linkedin.com/in/michelleccarey/\">Michelle Carey</a>, <a href=\"https://www.linkedin.com/in/jiahui-mavis-zhou-a4537814a\">Mavis Zhou</a>\n"]},{"cell_type":"markdown","id":"6ccde288-f907-4dd8-bed5-0a6d9b70fa5f","metadata":{},"outputs":[],"source":["<!--\n","## Change Log\n","\n","|  Date (YYYY-MM-DD) |  Version | Changed By  |  Change Description |\n","|---|---|---|---|\n","| 2020-09-23  | 2.0  | Shubham  |  Migrated Lab to Markdown and added to course repo in GitLab |\n","-->\n"]},{"cell_type":"markdown","id":"dae76ca9-618c-4880-9f03-49c2a45d1298","metadata":{},"outputs":[],"source":["<hr>\n"]},{"cell_type":"markdown","id":"aceef8f2-5216-4fff-80f7-284c2532f3ea","metadata":{},"outputs":[],"source":["\n","\n","\n","## <h3 align=\"center\"> &#169; IBM Corporation. All rights reserved. <h3/>\n"]}],"metadata":{"kernelspec":{"display_name":"Python","language":"python","name":"conda-env-python-py"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"prev_pub_hash":"37a863139f3354c1cef9ec278f05e4c8c62c9480611b948e6f14356b734d0e99"},"nbformat":4,"nbformat_minor":4}